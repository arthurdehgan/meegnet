{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18eb752b-3918-4b58-9cb1-56b9fde74e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.pyvenv/meegnet/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import configparser\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from meegnet_functions import load_single_subject\n",
    "from meegnet.parsing import parser, save_config\n",
    "from meegnet.network import Model\n",
    "from meegnet.utils import cuda_check\n",
    "from meegnet.viz import (\n",
    "    get_positive_negative_saliency,\n",
    "    compute_saliency_based_psd,\n",
    ")\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "\n",
    "\n",
    "LOG = logging.getLogger(\"meegnet\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %I:%M:%S %p\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee3cfb2-22e9-467b-b509-d7f5d1a2d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(\n",
    "    dataset,\n",
    "    labels,\n",
    "    sub,\n",
    "    sal_path,\n",
    "    net,\n",
    "    threshold,\n",
    "    w_size,\n",
    "    sfreq,\n",
    "    clf_type=\"\",\n",
    "    compute_psd=False,\n",
    "):\n",
    "\n",
    "    device = cuda_check()\n",
    "    GBP = GuidedBackpropReLUModel(net, device=device)\n",
    "\n",
    "    # Load all trials and corresponding labels for a specific subject.\n",
    "    data = dataset.data\n",
    "    targets = dataset.labels\n",
    "    if clf_type == \"eventclf\":\n",
    "        target_saliencies = [[[], []], [[], []]]\n",
    "        target_psd = [[[], []], [[], []]]\n",
    "    else:\n",
    "        target_saliencies = [[], []]\n",
    "        target_psd = [[], []]\n",
    "\n",
    "    # For each of those trial with associated label:\n",
    "    for trial, label in zip(data, targets):\n",
    "        X = trial\n",
    "        while len(X.shape) < 4:\n",
    "            X = X[np.newaxis, :]\n",
    "        X = X.to(device)\n",
    "        # Compute predictions of the trained network, and confidence\n",
    "        preds = torch.nn.Softmax(dim=1)(net(X)).detach().cpu()\n",
    "        pred = preds.argmax().item()\n",
    "        confidence = preds.max()\n",
    "        label = int(label)\n",
    "\n",
    "        # If the confidence reaches desired treshhold (given by args.confidence)\n",
    "        if confidence >= threshold and pred == label:\n",
    "            # Compute Guided Back-propagation for given label projected on given data X\n",
    "            guided_grads = GBP(X.to(device), label)\n",
    "            guided_grads = np.rollaxis(guided_grads, 2, 0)\n",
    "            # Compute saliencies\n",
    "            pos_saliency, neg_saliency = get_positive_negative_saliency(guided_grads)\n",
    "\n",
    "            # Depending on the task, add saliencies in lists\n",
    "            if clf_type == \"eventclf\":\n",
    "                target_saliencies[label][0].append(pos_saliency)\n",
    "                target_saliencies[label][1].append(neg_saliency)\n",
    "                if compute_psd:\n",
    "                    target_psd[label][0].append(\n",
    "                        compute_saliency_based_psd(pos_saliency, X, w_size, sfreq)\n",
    "                    )\n",
    "                    target_psd[label][1].append(\n",
    "                        compute_saliency_based_psd(neg_saliency, X, w_size, sfreq)\n",
    "                    )\n",
    "            else:\n",
    "                target_saliencies[0].append(pos_saliency)\n",
    "                target_saliencies[1].append(neg_saliency)\n",
    "                if compute_psd:\n",
    "                    target_psd[0].append(\n",
    "                        compute_saliency_based_psd(pos_saliency, X, w_size, sfreq)\n",
    "                    )\n",
    "                    target_psd[1].append(\n",
    "                        compute_saliency_based_psd(neg_saliency, X, w_size, sfreq)\n",
    "                    )\n",
    "    # With all saliencies computed, we save them in the specified save-path\n",
    "    n_saliencies = 0\n",
    "    n_saliencies += sum([len(e) for e in target_saliencies[0]])\n",
    "    n_saliencies += sum([len(e) for e in target_saliencies[1]])\n",
    "    LOG.info(f\"{n_saliencies} saliency maps computed for {sub}\")\n",
    "    for j, sal_type in enumerate((\"pos\", \"neg\")):\n",
    "        if clf_type == \"eventclf\":\n",
    "            for i, label in enumerate(labels):\n",
    "                sal_filepath = os.path.join(\n",
    "                    sal_path,\n",
    "                    f\"{sub}_{labels[i]}_{sal_type}_sal_{threshold}confidence.npy\",\n",
    "                )\n",
    "                np.save(sal_filepath, np.array(target_saliencies[i][j]))\n",
    "                if compute_psd:\n",
    "                    psd_filepath = os.path.join(\n",
    "                        psd_path,\n",
    "                        f\"{sub}_{labels[i]}_{sal_type}_psd_{threshold}confidence.npy\",\n",
    "                    )\n",
    "                    np.save(psd_filepath, np.array(target_psd[i][j]))\n",
    "        else:\n",
    "            lab = \"\" if clf_type == \"subclf\" else f\"_{labels[label]}\"\n",
    "            sal_filepath = os.path.join(\n",
    "                sal_path,\n",
    "                f\"{sub}{lab}_{sal_type}_sal_{threshold}confidence.npy\",\n",
    "            )\n",
    "            np.save(sal_filepath, np.array(target_saliencies[j]))\n",
    "            if compute_psd:\n",
    "                lab = \"\" if clf_type == \"subclf\" else f\"_{labels[label]}\"\n",
    "                psd_filepath = os.path.join(\n",
    "                    psd_path,\n",
    "                    f\"{sub}{lab}_{sal_type}_psd_{threshold}confidence.npy\",\n",
    "                )\n",
    "                np.save(psd_filepath, np.array(target_psd[j]))\n",
    "\n",
    "def get_saliency_data(saliency_dict, option):\n",
    "    if option in (\"pos\", \"neg\"):\n",
    "        return saliency_dict[option]\n",
    "    else:\n",
    "        saliencies = {}\n",
    "        if option == \"sum\":\n",
    "            operation = lambda a, b: a + b\n",
    "        else:\n",
    "            operation = lambda a, b: a - b\n",
    "        for lab, pos in saliency_dict[\"pos\"].items():\n",
    "            saliencies[lab] = operation(np.array(pos), np.array(saliency_dict[\"neg\"][lab]))\n",
    "    return saliencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bba896-da3a-47e0-a9d7-497439fd49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# PARSING #\n",
    "###########\n",
    "\n",
    "# For Jupyter Notebook Only: we create fake args\n",
    "argstring = \"--config ../scripts/eventclf.ini\".split()\n",
    "args = parser.parse_args(argstring)\n",
    "save_config(vars(args), args.config)\n",
    "default_values = configparser.ConfigParser()\n",
    "default_values.read(\"../default_values.ini\")\n",
    "default_values = default_values[\"config\"]\n",
    "\n",
    "fold = None if args.fold == -1 else int(args.fold)\n",
    "if args.clf_type == \"eventclf\":\n",
    "    assert (\n",
    "        args.datatype != \"rest\"\n",
    "    ), \"datatype must be set to passive in order to run event classification\"\n",
    "\n",
    "if args.feature == \"bins\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_BINS\"]\n",
    "elif args.feature == \"bands\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_BANDS\"]\n",
    "elif args.feature == \"temporal\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_TIME\"]\n",
    "\n",
    "if args.clf_type == \"subclf\":\n",
    "    trial_length = int(args.segment_length * args.sfreq)\n",
    "if args.clf_type == \"eventclf\":\n",
    "    labels = [\"visual\", \"auditory\"]\n",
    "else:\n",
    "    labels = []\n",
    "    \n",
    "if args.feature == \"bins\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_BINS\"]\n",
    "elif args.feature == \"bands\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_BANDS\"]\n",
    "elif args.feature == \"temporal\":\n",
    "    trial_length = default_values[\"TRIAL_LENGTH_TIME\"]\n",
    "\n",
    "if args.sensors == \"MAG\":\n",
    "    n_channels = default_values[\"N_CHANNELS_MAG\"]\n",
    "    chan_index = [0]\n",
    "elif args.sensors == \"GRAD\":\n",
    "    n_channels = default_values[\"N_CHANNELS_GRAD\"]\n",
    "    chan_index = [1, 2]\n",
    "else:\n",
    "    n_channels = default_values[\"N_CHANNELS_OTHER\"]\n",
    "    chan_index = [0, 1, 2]\n",
    "\n",
    "input_size = (n_channels // 102, 102, trial_length)\n",
    "\n",
    "name = f\"{args.clf_type}_{args.model_name}_{args.seed}_{args.sensors}\"\n",
    "suffixes = \"\"\n",
    "if args.net_option == \"custom_net\":\n",
    "    if args.batchnorm:\n",
    "        suffixes += \"_BN\"\n",
    "    if args.maxpool != 0:\n",
    "        suffixes += f\"_maxpool{args.maxpool}\"\n",
    "\n",
    "    name += f\"_dropout{args.dropout}_filter{args.filters}_nchan{args.nchan}_lin{args.linear}_depth{args.hlayers}\"\n",
    "    name += suffixes\n",
    "\n",
    "n_samples = None if int(args.n_samples) == -1 else int(args.n_samples)\n",
    "if args.clf_type == \"subclf\":\n",
    "    data_path = os.path.join(args.save_path, f\"downsampled_{args.sfreq}\")\n",
    "    n_subjects = len(os.listdir(data_path))\n",
    "    n_outputs = min(n_subjects, args.max_subj)\n",
    "    lso = False\n",
    "else:\n",
    "    n_outputs = 2\n",
    "    lso = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d424c38-7987-452e-9221-58ea5d41ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "### PREPARING SAVE FOLDERS ###\n",
    "##############################\n",
    "\n",
    "if args.compute_psd:\n",
    "    psd_path = os.path.join(args.save_path, \"saliency_based_psds\", name)\n",
    "    if not os.path.exists(psd_path):\n",
    "        os.makedirs(psd_path)\n",
    "\n",
    "sal_path = os.path.join(args.save_path, \"saliency_maps\", name)\n",
    "if not os.path.exists(sal_path):\n",
    "    os.makedirs(sal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cf9d96-8563-4075-a0cf-b7964fb0dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/16/2024 10:05:22 PM => loading checkpoint '/home/arthur/.cache/huggingface/hub/models--lamaroufle--meegnet/snapshots/5f96fe8d1b9ce85462329cdb3f148e83d3383873/eventclf_meegnet_3_102_400_2.pt'\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### LOADING MODEL ###\n",
    "#####################\n",
    "\n",
    "if args.model_path is None:\n",
    "    model_path = args.save_path\n",
    "else:\n",
    "    model_path = args.model_path\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    LOG.info(f\"{model_path} does not exist. Creating folders\")\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "my_model = Model(name, args.net_option, input_size, n_outputs, save_path=args.save_path)\n",
    "my_model.from_pretrained()\n",
    "# my_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41183957-7172-48e3-9f73-4eacb52e6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### PRELOADING DATA ###\n",
    "#######################\n",
    "\n",
    "csv_file = os.path.join(args.save_path, f\"participants_info.csv\")\n",
    "dataframe = (\n",
    "    pd.read_csv(csv_file, index_col=0)\n",
    "    .sample(frac=1, random_state=args.seed)\n",
    "    .reset_index(drop=True)[: args.max_subj]\n",
    ")\n",
    "subj_list = dataframe[\"sub\"]\n",
    "np.random.seed(args.seed)\n",
    "random_subject_idx = np.random.choice(np.arange(len(subj_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69178e51-7074-4f0b-a32f-3f1caf9d24e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/16/2024 10:05:23 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:23 PM Loading subject CC410220\n",
      "07/16/2024 10:05:25 PM 206 saliency maps computed for CC410220\n",
      "07/16/2024 10:05:25 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:25 PM Loading subject CC221324\n",
      "07/16/2024 10:05:26 PM 238 saliency maps computed for CC221324\n",
      "07/16/2024 10:05:26 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:26 PM Loading subject CC310252\n",
      "07/16/2024 10:05:27 PM 218 saliency maps computed for CC310252\n",
      "07/16/2024 10:05:27 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:27 PM Loading subject CC420167\n",
      "07/16/2024 10:05:28 PM 210 saliency maps computed for CC420167\n",
      "07/16/2024 10:05:28 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:28 PM Loading subject CC722891\n",
      "07/16/2024 10:05:29 PM 238 saliency maps computed for CC722891\n",
      "07/16/2024 10:05:30 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:30 PM Loading subject CC620429\n",
      "07/16/2024 10:05:31 PM 240 saliency maps computed for CC620429\n",
      "07/16/2024 10:05:31 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:31 PM Loading subject CC510648\n",
      "07/16/2024 10:05:32 PM 198 saliency maps computed for CC510648\n",
      "07/16/2024 10:05:32 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:32 PM Loading subject CC420322\n",
      "07/16/2024 10:05:33 PM 236 saliency maps computed for CC420322\n",
      "07/16/2024 10:05:33 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:33 PM Loading subject CC620073\n",
      "07/16/2024 10:05:34 PM 226 saliency maps computed for CC620073\n",
      "07/16/2024 10:05:34 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:34 PM Loading subject CC310008\n",
      "07/16/2024 10:05:35 PM 234 saliency maps computed for CC310008\n",
      "07/16/2024 10:05:35 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:35 PM Loading subject CC110182\n",
      "07/16/2024 10:05:36 PM 218 saliency maps computed for CC110182\n",
      "07/16/2024 10:05:37 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:37 PM Loading subject CC221107\n",
      "07/16/2024 10:05:38 PM 232 saliency maps computed for CC221107\n",
      "07/16/2024 10:05:38 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:38 PM Loading subject CC321899\n",
      "07/16/2024 10:05:39 PM 212 saliency maps computed for CC321899\n",
      "07/16/2024 10:05:39 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:39 PM Loading subject CC210088\n",
      "07/16/2024 10:05:41 PM 212 saliency maps computed for CC210088\n",
      "07/16/2024 10:05:41 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:41 PM Loading subject CC120061\n",
      "07/16/2024 10:05:42 PM 200 saliency maps computed for CC120061\n",
      "07/16/2024 10:05:42 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:42 PM Loading subject CC120065\n",
      "07/16/2024 10:05:43 PM 236 saliency maps computed for CC120065\n",
      "07/16/2024 10:05:43 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:43 PM Loading subject CC720329\n",
      "07/16/2024 10:05:44 PM 224 saliency maps computed for CC720329\n",
      "07/16/2024 10:05:44 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:44 PM Loading subject CC120727\n",
      "07/16/2024 10:05:45 PM 218 saliency maps computed for CC120727\n",
      "07/16/2024 10:05:45 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:45 PM Loading subject CC320002\n",
      "07/16/2024 10:05:47 PM 230 saliency maps computed for CC320002\n",
      "07/16/2024 10:05:47 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:47 PM Loading subject CC720774\n",
      "07/16/2024 10:05:48 PM 196 saliency maps computed for CC720774\n",
      "07/16/2024 10:05:48 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:48 PM Loading subject CC222956\n",
      "07/16/2024 10:05:50 PM 226 saliency maps computed for CC222956\n",
      "07/16/2024 10:05:50 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:50 PM Loading subject CC420231\n",
      "07/16/2024 10:05:51 PM 216 saliency maps computed for CC420231\n",
      "07/16/2024 10:05:52 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:52 PM Loading subject CC310463\n",
      "07/16/2024 10:05:53 PM 212 saliency maps computed for CC310463\n",
      "07/16/2024 10:05:53 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:53 PM Loading subject CC320814\n",
      "07/16/2024 10:05:54 PM 236 saliency maps computed for CC320814\n",
      "07/16/2024 10:05:54 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:54 PM Loading subject CC510534\n",
      "07/16/2024 10:05:55 PM 238 saliency maps computed for CC510534\n",
      "07/16/2024 10:05:55 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:55 PM Loading subject CC221209\n",
      "07/16/2024 10:05:56 PM 228 saliency maps computed for CC221209\n",
      "07/16/2024 10:05:56 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:56 PM Loading subject CC610028\n",
      "07/16/2024 10:05:57 PM 184 saliency maps computed for CC610028\n",
      "07/16/2024 10:05:57 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:57 PM Loading subject CC120182\n",
      "07/16/2024 10:05:59 PM 228 saliency maps computed for CC120182\n",
      "07/16/2024 10:05:59 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:05:59 PM Loading subject CC322186\n",
      "07/16/2024 10:06:00 PM 224 saliency maps computed for CC322186\n",
      "07/16/2024 10:06:00 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:00 PM Loading subject CC420137\n",
      "07/16/2024 10:06:01 PM 218 saliency maps computed for CC420137\n",
      "07/16/2024 10:06:01 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:01 PM Loading subject CC312149\n",
      "07/16/2024 10:06:03 PM 214 saliency maps computed for CC312149\n",
      "07/16/2024 10:06:03 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:03 PM Loading subject CC210617\n",
      "07/16/2024 10:06:04 PM 236 saliency maps computed for CC210617\n",
      "07/16/2024 10:06:05 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:05 PM Loading subject CC510355\n",
      "07/16/2024 10:06:06 PM 234 saliency maps computed for CC510355\n",
      "07/16/2024 10:06:06 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:06 PM Loading subject CC510304\n",
      "07/16/2024 10:06:07 PM 182 saliency maps computed for CC510304\n",
      "07/16/2024 10:06:07 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:07 PM Loading subject CC410091\n",
      "07/16/2024 10:06:08 PM 226 saliency maps computed for CC410091\n",
      "07/16/2024 10:06:08 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:08 PM Loading subject CC220635\n",
      "07/16/2024 10:06:10 PM 236 saliency maps computed for CC220635\n",
      "07/16/2024 10:06:10 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:10 PM Loading subject CC510486\n",
      "07/16/2024 10:06:11 PM 180 saliency maps computed for CC510486\n",
      "07/16/2024 10:06:11 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:11 PM Loading subject CC420364\n",
      "07/16/2024 10:06:12 PM 234 saliency maps computed for CC420364\n",
      "07/16/2024 10:06:12 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:12 PM Loading subject CC620193\n",
      "07/16/2024 10:06:13 PM 194 saliency maps computed for CC620193\n",
      "07/16/2024 10:06:13 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:13 PM Loading subject CC321880\n",
      "07/16/2024 10:06:14 PM 218 saliency maps computed for CC321880\n",
      "07/16/2024 10:06:14 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:14 PM Loading subject CC320297\n",
      "07/16/2024 10:06:15 PM 190 saliency maps computed for CC320297\n",
      "07/16/2024 10:06:15 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:15 PM Loading subject CC610625\n",
      "07/16/2024 10:06:17 PM 228 saliency maps computed for CC610625\n",
      "07/16/2024 10:06:17 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:17 PM Loading subject CC610288\n",
      "07/16/2024 10:06:18 PM 240 saliency maps computed for CC610288\n",
      "07/16/2024 10:06:18 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:18 PM Loading subject CC420462\n",
      "07/16/2024 10:06:19 PM 226 saliency maps computed for CC420462\n",
      "07/16/2024 10:06:19 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:19 PM Loading subject CC720071\n",
      "07/16/2024 10:06:20 PM 230 saliency maps computed for CC720071\n",
      "07/16/2024 10:06:20 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:20 PM Loading subject CC620793\n",
      "07/16/2024 10:06:21 PM 220 saliency maps computed for CC620793\n",
      "07/16/2024 10:06:22 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:22 PM Loading subject CC720497\n",
      "07/16/2024 10:06:23 PM 234 saliency maps computed for CC720497\n",
      "07/16/2024 10:06:23 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:23 PM Loading subject CC510483\n",
      "07/16/2024 10:06:24 PM 220 saliency maps computed for CC510483\n",
      "07/16/2024 10:06:24 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:24 PM Loading subject CC420089\n",
      "07/16/2024 10:06:26 PM 230 saliency maps computed for CC420089\n",
      "07/16/2024 10:06:26 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:26 PM Loading subject CC320621\n",
      "07/16/2024 10:06:27 PM 198 saliency maps computed for CC320621\n",
      "07/16/2024 10:06:27 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:27 PM Loading subject CC420004\n",
      "07/16/2024 10:06:28 PM 184 saliency maps computed for CC420004\n",
      "07/16/2024 10:06:28 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:28 PM Loading subject CC720941\n",
      "07/16/2024 10:06:29 PM 220 saliency maps computed for CC720941\n",
      "07/16/2024 10:06:29 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:29 PM Loading subject CC711245\n",
      "07/16/2024 10:06:31 PM 216 saliency maps computed for CC711245\n",
      "07/16/2024 10:06:31 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:31 PM Loading subject CC520424\n",
      "07/16/2024 10:06:32 PM 230 saliency maps computed for CC520424\n",
      "07/16/2024 10:06:32 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:32 PM Loading subject CC510480\n",
      "07/16/2024 10:06:33 PM 88 saliency maps computed for CC510480\n",
      "07/16/2024 10:06:33 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:33 PM Loading subject CC721292\n",
      "07/16/2024 10:06:35 PM 232 saliency maps computed for CC721292\n",
      "07/16/2024 10:06:35 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:35 PM Loading subject CC620885\n",
      "07/16/2024 10:06:36 PM 212 saliency maps computed for CC620885\n",
      "07/16/2024 10:06:36 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:36 PM Loading subject CC620090\n",
      "07/16/2024 10:06:38 PM 194 saliency maps computed for CC620090\n",
      "07/16/2024 10:06:38 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:38 PM Loading subject CC520562\n",
      "07/16/2024 10:06:39 PM 240 saliency maps computed for CC520562\n",
      "07/16/2024 10:06:39 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:39 PM Loading subject CC320850\n",
      "07/16/2024 10:06:41 PM 234 saliency maps computed for CC320850\n",
      "07/16/2024 10:06:41 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:41 PM Loading subject CC120137\n",
      "07/16/2024 10:06:42 PM 124 saliency maps computed for CC120137\n",
      "07/16/2024 10:06:42 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:42 PM Loading subject CC520607\n",
      "07/16/2024 10:06:44 PM 240 saliency maps computed for CC520607\n",
      "07/16/2024 10:06:44 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:44 PM Loading subject CC410286\n",
      "07/16/2024 10:06:45 PM 212 saliency maps computed for CC410286\n",
      "07/16/2024 10:06:45 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:45 PM Loading subject CC321137\n",
      "07/16/2024 10:06:47 PM 216 saliency maps computed for CC321137\n",
      "07/16/2024 10:06:47 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:47 PM Loading subject CC720646\n",
      "07/16/2024 10:06:49 PM 236 saliency maps computed for CC720646\n",
      "07/16/2024 10:06:49 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:49 PM Loading subject CC420182\n",
      "07/16/2024 10:06:50 PM 234 saliency maps computed for CC420182\n",
      "07/16/2024 10:06:50 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:50 PM Loading subject CC520585\n",
      "07/16/2024 10:06:51 PM 226 saliency maps computed for CC520585\n",
      "07/16/2024 10:06:51 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:51 PM Loading subject CC610631\n",
      "07/16/2024 10:06:52 PM 220 saliency maps computed for CC610631\n",
      "07/16/2024 10:06:53 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:53 PM Loading subject CC222120\n",
      "07/16/2024 10:06:54 PM 206 saliency maps computed for CC222120\n",
      "07/16/2024 10:06:54 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:54 PM Loading subject CC720407\n",
      "07/16/2024 10:06:56 PM 240 saliency maps computed for CC720407\n",
      "07/16/2024 10:06:56 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:56 PM Loading subject CC620354\n",
      "07/16/2024 10:06:57 PM 234 saliency maps computed for CC620354\n",
      "07/16/2024 10:06:57 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:57 PM Loading subject CC221031\n",
      "07/16/2024 10:06:59 PM 234 saliency maps computed for CC221031\n",
      "07/16/2024 10:06:59 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:06:59 PM Loading subject CC320342\n",
      "07/16/2024 10:07:00 PM 224 saliency maps computed for CC320342\n",
      "07/16/2024 10:07:01 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:01 PM Loading subject CC120347\n",
      "07/16/2024 10:07:02 PM 220 saliency maps computed for CC120347\n",
      "07/16/2024 10:07:02 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:02 PM Loading subject CC420241\n",
      "07/16/2024 10:07:03 PM 230 saliency maps computed for CC420241\n",
      "07/16/2024 10:07:03 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:03 PM Loading subject CC220198\n",
      "07/16/2024 10:07:04 PM 218 saliency maps computed for CC220198\n",
      "07/16/2024 10:07:04 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:04 PM Loading subject CC223085\n",
      "07/16/2024 10:07:05 PM 140 saliency maps computed for CC223085\n",
      "07/16/2024 10:07:05 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:05 PM Loading subject CC510039\n",
      "07/16/2024 10:07:07 PM 218 saliency maps computed for CC510039\n",
      "07/16/2024 10:07:07 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:07 PM Loading subject CC121317\n",
      "07/16/2024 10:07:08 PM 228 saliency maps computed for CC121317\n",
      "07/16/2024 10:07:09 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:09 PM Loading subject CC510639\n",
      "07/16/2024 10:07:10 PM 214 saliency maps computed for CC510639\n",
      "07/16/2024 10:07:10 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:10 PM Loading subject CC220506\n",
      "07/16/2024 10:07:11 PM 136 saliency maps computed for CC220506\n",
      "07/16/2024 10:07:11 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:11 PM Loading subject CC320608\n",
      "07/16/2024 10:07:13 PM 206 saliency maps computed for CC320608\n",
      "07/16/2024 10:07:13 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:13 PM Loading subject CC420143\n",
      "07/16/2024 10:07:14 PM 224 saliency maps computed for CC420143\n",
      "07/16/2024 10:07:14 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:14 PM Loading subject CC120309\n",
      "07/16/2024 10:07:15 PM 228 saliency maps computed for CC120309\n",
      "07/16/2024 10:07:15 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:15 PM Loading subject CC721374\n",
      "07/16/2024 10:07:16 PM 234 saliency maps computed for CC721374\n",
      "07/16/2024 10:07:17 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:17 PM Loading subject CC121479\n",
      "07/16/2024 10:07:18 PM 212 saliency maps computed for CC121479\n",
      "07/16/2024 10:07:18 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:18 PM Loading subject CC420060\n",
      "07/16/2024 10:07:19 PM 228 saliency maps computed for CC420060\n",
      "07/16/2024 10:07:19 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:19 PM Loading subject CC620405\n",
      "07/16/2024 10:07:21 PM 238 saliency maps computed for CC620405\n",
      "07/16/2024 10:07:21 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:21 PM Loading subject CC320568\n",
      "07/16/2024 10:07:22 PM 238 saliency maps computed for CC320568\n",
      "07/16/2024 10:07:22 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:22 PM Loading subject CC710446\n",
      "07/16/2024 10:07:23 PM 232 saliency maps computed for CC710446\n",
      "07/16/2024 10:07:23 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:23 PM Loading subject CC620279\n",
      "07/16/2024 10:07:24 PM 194 saliency maps computed for CC620279\n",
      "07/16/2024 10:07:24 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:24 PM Loading subject CC121428\n",
      "07/16/2024 10:07:26 PM 192 saliency maps computed for CC121428\n",
      "07/16/2024 10:07:26 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:26 PM Loading subject CC610469\n",
      "07/16/2024 10:07:27 PM 240 saliency maps computed for CC610469\n",
      "07/16/2024 10:07:27 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:27 PM Loading subject CC420071\n",
      "07/16/2024 10:07:28 PM 240 saliency maps computed for CC420071\n",
      "07/16/2024 10:07:28 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:28 PM Loading subject CC410101\n",
      "07/16/2024 10:07:29 PM 228 saliency maps computed for CC410101\n",
      "07/16/2024 10:07:29 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:29 PM Loading subject CC510342\n",
      "07/16/2024 10:07:30 PM 210 saliency maps computed for CC510342\n",
      "07/16/2024 10:07:30 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:30 PM Loading subject CC210124\n",
      "07/16/2024 10:07:32 PM 232 saliency maps computed for CC210124\n",
      "07/16/2024 10:07:32 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:32 PM Loading subject CC510321\n",
      "07/16/2024 10:07:33 PM 188 saliency maps computed for CC510321\n",
      "07/16/2024 10:07:33 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:33 PM Loading subject CC620821\n",
      "07/16/2024 10:07:34 PM 224 saliency maps computed for CC620821\n",
      "07/16/2024 10:07:34 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:34 PM Loading subject CC610210\n",
      "07/16/2024 10:07:35 PM 188 saliency maps computed for CC610210\n",
      "07/16/2024 10:07:35 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:35 PM Loading subject CC420392\n",
      "07/16/2024 10:07:37 PM 228 saliency maps computed for CC420392\n",
      "07/16/2024 10:07:37 PM Logging subjects and labels from /home/arthur/data...\n",
      "07/16/2024 10:07:37 PM Loading subject CC510161\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### COMPUTING SALIENCIES ###\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m subj_list:\n\u001b[0;32m----> 6\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_single_subject\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlso\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     compute_saliency_maps(\n\u001b[1;32m      8\u001b[0m         dataset,\n\u001b[1;32m      9\u001b[0m         labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         args\u001b[38;5;241m.\u001b[39mcompute_psd,\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m~/github/meegnet/notebooks/meegnet_functions.py:25\u001b[0m, in \u001b[0;36mload_single_subject\u001b[0;34m(sub, n_samples, lso, args)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m Dataset(\n\u001b[1;32m     18\u001b[0m         sfreq\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msfreq,\n\u001b[1;32m     19\u001b[0m         n_subjects\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_subj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         random_state\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseed,\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_sub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/.pyvenv/meegnet/lib/python3.12/site-packages/meegnet/dataloaders.py:241\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, data_path, csv_path, one_sub)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_list:\n\u001b[1;32m    240\u001b[0m     row \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mloc[dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m sub]\n\u001b[0;32m--> 241\u001b[0m     sub_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyvenv/meegnet/lib/python3.12/site-packages/meegnet/dataloaders.py:323\u001b[0m, in \u001b[0;36mDataset._load_sub\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads a subject's data.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    _description_\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     LOG\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a problem loading subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyvenv/meegnet/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:484\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    482\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.pyvenv/meegnet/lib/python3.12/site-packages/numpy/lib/format.py:834\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    846\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    847\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################\n",
    "### COMPUTING SALIENCIES ###\n",
    "############################\n",
    "\n",
    "for sub in subj_list:\n",
    "    dataset = load_single_subject(sub, n_samples, lso, args)\n",
    "    compute_saliency_maps(\n",
    "        dataset,\n",
    "        labels,\n",
    "        sub,\n",
    "        sal_path,\n",
    "        my_model.net,\n",
    "        args.confidence,\n",
    "        args.w_size,\n",
    "        args.sfreq,\n",
    "        args.clf_type,\n",
    "        args.compute_psd,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b638ce1-78e3-434d-a376-8fa4707c4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### HARD CODED VALUES ###\n",
    "#########################\n",
    "\n",
    "# TODO add those to a TOML file, either config or default_values\n",
    "sensors = [\"MAG\", \"PLANNAR1\", \"PLANNAR2\"]\n",
    "cmap = \"coolwarm\"\n",
    "stim_tick = 75\n",
    "saliency_types = (\"pos\", \"neg\")\n",
    "saliency_options = (\"pos\", \"neg\", \"sum\", \"diff\")\n",
    "\n",
    "# Some tested aletrnatives for the colormap:\n",
    "# cmap = sns.color_palette(\"icefire\", as_cmap=True)\n",
    "# cmap = sns.color_palette(\"coolwarm\", as_cmap=True, center=\"dark\")\n",
    "# cmap = \"inferno\"\n",
    "# cmap = \"seismic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402f715-4db1-4576-be7c-49822faf31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### GENERATING FIGURES ###\n",
    "##########################\n",
    "\n",
    "all_saliencies = defaultdict(lambda: defaultdict(lambda: []))\n",
    "\n",
    "LOG.info(f\"Generating figure for sensors: {sensors}\")\n",
    "LOG.info(f\"For the {args.clf_type} classification\")\n",
    "\n",
    "# label contains same information as sub for subclf but we only load files that have label == sub\n",
    "for i, sub in enumerate(subj_list):\n",
    "    sub_saliencies = defaultdict(lambda: {})\n",
    "    for label in labels:\n",
    "        if args.clf_type == \"subclf\":\n",
    "            if label != sub:\n",
    "                continue\n",
    "        nofile = False\n",
    "\n",
    "        for saliency_type in saliency_types:\n",
    "            lab = \"\" if args.clf_type == \"subclf\" else f\"_{label}\"\n",
    "            saliency_file = os.path.join(\n",
    "                sal_path,\n",
    "                f\"{sub}{lab}_{saliency_type}_sal_{args.confidence}confidence.npy\",\n",
    "            )\n",
    "            if os.path.exists(saliency_file):\n",
    "                try:\n",
    "                    saliencies = np.load(saliency_file)\n",
    "                    sub_saliencies[saliency_type][label] = saliencies\n",
    "                except IOError:\n",
    "                    logging.warning(f\"Error loading {saliency_file}\")\n",
    "                    nofile = True\n",
    "                    continue\n",
    "            else:\n",
    "                nofile = True\n",
    "                continue\n",
    "            if len(saliencies.shape) == 3:\n",
    "                saliencies = saliencies[np.newaxis, ...]  # If only one saliency in file\n",
    "            elif len(saliencies.shape) != 4:\n",
    "                nofile = True\n",
    "                continue\n",
    "            all_saliencies[saliency_type][label].append(saliencies.mean(axis=0))\n",
    "\n",
    "        if nofile:\n",
    "            continue\n",
    "        if args.clf_type == \"subclf\":\n",
    "            break  # we only need to add one label per subject so we get out of the loop\n",
    "\n",
    "    skip = False\n",
    "    for option in saliency_options:\n",
    "        if i == random_subject_idx:\n",
    "            data_dict = get_saliency_data(sub_saliencies, option)\n",
    "            for val in data_dict.values():\n",
    "                if val.size == 0:\n",
    "                    skip = True\n",
    "                    break\n",
    "            temp = {\n",
    "                key: val[np.random.choice(np.arange(len(val)))]\n",
    "                for key, val in data_dict.items()\n",
    "            }\n",
    "            out_path = generate_saliency_figure(\n",
    "                temp,\n",
    "                info_path=args.raw_path,\n",
    "                save_path=visu_path,\n",
    "                suffix=f\"{args.clf_type}_{sub}_single_trial_{option}\",\n",
    "                sensors=sensors,\n",
    "                title=f\"{option} saliencies for a single trial of subject {sub}\",\n",
    "                clf_type=args.clf_type,\n",
    "                cmap=cmap,\n",
    "                stim_tick=stim_tick,\n",
    "            )\n",
    "            logging.info(f\"Figure generated: {out_path}\")\n",
    "            temp = {key: np.mean(val, axis=0) for key, val in data_dict.items()}\n",
    "            out_path = generate_saliency_figure(\n",
    "                temp,\n",
    "                info_path=args.raw_path,\n",
    "                save_path=visu_path,\n",
    "                suffix=f\"{args.clf_type}_{sub}_all_trials_{option}\",\n",
    "                sensors=sensors,\n",
    "                title=f\"{option} saliencies for the averaged trials of subject {sub}\",\n",
    "                clf_type=args.clf_type,\n",
    "                cmap=cmap,\n",
    "                stim_tick=stim_tick,\n",
    "            )\n",
    "            logging.info(f\"Figure generated: {out_path}\")\n",
    "    if skip:\n",
    "        random_subject_idx += 1\n",
    "        continue\n",
    "\n",
    "for label in labels:\n",
    "    for saliency_type in saliency_types:\n",
    "        if type(all_saliencies[saliency_type][label]) == list:\n",
    "            all_saliencies[saliency_type][label] = np.array(\n",
    "                all_saliencies[saliency_type][label]\n",
    "            )\n",
    "for option in saliency_options:\n",
    "    data_dict = get_saliency_data(all_saliencies, option)\n",
    "    # np.newaxis here is a quick fix to a problem that might stick with other clf types\n",
    "    final_dict = {key: np.mean(val, axis=0)[np.newaxis] for key, val in data_dict.items()}\n",
    "    if args.clf_type == \"subclf\":\n",
    "        final_dict = {\"all_subj\": np.mean(list(final_dict.values()), axis=0)}\n",
    "        labels = [\"all_subj\"]\n",
    "\n",
    "    out_path = generate_saliency_figure(\n",
    "        final_dict,\n",
    "        info_path=args.raw_path,\n",
    "        save_path=visu_path,\n",
    "        suffix=f\"{args.clf_type}_{option}\",\n",
    "        sensors=sensors,\n",
    "        title=f\"{option} saliencies averaged across all subjects\",\n",
    "        clf_type=args.clf_type,\n",
    "        cmap=cmap,\n",
    "        stim_tick=stim_tick,\n",
    "    )\n",
    "    logging.info(f\"Figure generated: {out_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
