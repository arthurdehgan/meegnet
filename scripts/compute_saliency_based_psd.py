from collections.abc import Iterable
import numpy as np
import pandas as pd
import torch
import os
from joblib import Parallel, delayed, parallel_backend
from camcan.params import TIME_TRIAL_LENGTH
from camcan.utils import compute_psd
from camcan.parsing import parser
from camcan.network import create_net
from camcan.misc_functions import get_positive_negative_saliency
from camcan.utils import load_checkpoint, cuda_check
from visu_filter_outputs import load_data


DEVICE = "cpu"
LABELS = ["image", "sound"]  # image is label 0 and sound label 1


def choose_best_window(data, fs=500, w_size=300):
    """
    data: array
        Must be of size k x n_samples. k can be sensor dimension or trial dimension.
    w_size: int
        The size of the window in ms
    """
    masks = [dat >= (np.mean(dat) + np.std(dat) / 2) for dat in data]
    w_size = int(w_size * fs / 1000)
    best_window_idx = []
    for mask in masks:
        windows = np.array([mask[i : i + w_size] for i in range(len(mask) - w_size)])
        values = [sum(window) for window in windows]
        best_window_index = np.where(values == max(values))[0]
        if len(best_window_index) > 1:
            idx_range = best_window_index[-1] - best_window_index[0]
            if idx_range <= 150 * fs / 1000:  # 150ms betweeen first and last window
                # Then best would be in the middle of all this
                best = int(len(best_window_index) / 2)
                best_window_idx.append(best_window_index[best])
            elif idx_range <= 300 * fs / 1000:  # 300ms
                best_window_idx.append((best_window_index[0], best_window_index[-1]))
            else:
                best = int(len(best_window_index) / 2)
                best_window_idx.append(
                    (best_window_index[0], best, best_window_index[-1])
                )
        else:
            best_window_idx.append(best_window_index[0])
    return best_window_idx


def compute_psd_windows(saliency):
    chan_data = []
    for chan in saliency:
        windows_idx = choose_best_window(chan)
        transformed_data = []
        for j, index in enumerate(windows_idx):
            if isinstance(index, Iterable):
                tmp = []
                for idx in index:
                    tmp.append(
                        compute_psd(
                            chan[j, idx : idx + w_size].reshape(1, w_size),
                            fs=fs,
                        )
                    )
                bands = np.mean(tmp, axis=0)
            else:
                bands = compute_psd(
                    chan[j, index : index + w_size].reshape(1, w_size),
                    fs=fs,
                )
            transformed_data.append(bands)
        chan_data.append(np.array(transformed_data).squeeze())
    return np.array(chan_data)


def compute_the_good_stuff(
    net, trial, y, w_size, fs, use_windows=False, sal_option="pos"
):
    X = torch.Tensor(trial[np.newaxis])
    X.requires_grad_(True)
    # If confidence is good enough we use the trial for visualization
    confidence = torch.nn.Softmax(dim=1)(net(X)).max()
    if confidence >= 0.95:
        if use_windows:
            GBP = GuidedBackprop(net)
            guided_grads = GBP.generate_gradients(X, y)
            pos_saliency, neg_saliency = get_positive_negative_saliency(guided_grads)
            if sal_option == "pos":
                saliency = pos_saliency
            elif sal_option == "neg":
                saliency = neg_saliency
            elif sal_option == "both":
                saliencies = (
                    compute_psd_windows(pos_saliency),
                    compute_psd_windows(neg_saliency),
                )
                return saliencies
            else:
                saliency = pos_saliency + neg_saliency
            return compute_psd_windows(saliency)
        else:
            return compute_psd(trial, fs=fs)
    else:
        return None


if __name__ == "__main__":
    parser.add_argument(
        "--use-windows",
        action="store_true",
        help="wether or not to use saliency windows generated by guided backprop.",
    )
    parser.add_argument(
        "--topomaps",
        action="store_true",
        help="wether or not to generate topomaps for the spatial layer.",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Will generate all programmed visualizations.",
    )
    parser.add_argument(
        "--spectral",
        action="store_true",
        help="for topograd and backprop, if set will do everything in spectral domain after welch transform. if not set, temporal.",
    )
    parser.add_argument(
        "--backprop",
        action="store_true",
        help="wether or not to generate the backprop filter.",
    )
    parser.add_argument(
        "--topograd",
        action="store_true",
        help="wether or not to generate the topomaps of the guided backprop.",
    )
    parser.add_argument(
        "--outputs",
        action="store_true",
        help="wether or not to generate the outputs of the conv layers.",
    )
    parser.add_argument(
        "--saliency",
        default="pos",
        choices=["pos", "neg", "both"],
        type=str,
        help="chooses whether to use positive saliency, negative saliency or the sum of them",
    )
    args = parser.parse_args()

    suffixes = ""
    if args.batchnorm:
        suffixes += "_BN"
    if args.maxpool != 0:
        suffixes += f"_maxpool{args.maxpool}"

    # WARNING: using an older version of networks: fold was saved from 0 to 4 instead of 1 to 5 !! TODO
    name = f"{args.model_name}_{args.seed}_fold{args.fold}_{args.sensors}_dropout{args.dropout}_filter{args.filters}_nchan{args.nchan}_lin{args.linear}_depth{args.hlayers}"
    name += suffixes

    if args.feature == "bins":
        trial_length = 241
    if args.feature == "bands":
        trial_length = 5
    elif args.feature == "temporal":
        trial_length = TIME_TRIAL_LENGTH
    elif args.feature == "cov":
        # TODO
        pass
    elif args.feature == "cosp":
        # TODO
        pass

    if args.sensors == "MAG":
        n_channels = 102
    elif args.sensors == "GRAD":
        n_channels = 204
    elif args.sensors == "ALL":
        n_channels = 306

    if args.subclf:
        # TODO
        raise "not yet implemented for subclf"
    else:
        n_outputs = 2

    input_size = (n_channels // 102, 102, trial_length)
    model_filepath = os.path.join("../models/", name + ".pt")

    net = create_net(args.net_option, name, input_size, n_outputs, args)
    epoch, net_state, optimizer_state = load_checkpoint(model_filepath)
    net.load_state_dict(net_state)
    net.to(DEVICE)

    dataframe = pd.read_csv(f"{args.path}clean_participant_new.csv", index_col=0)
    subj_list = dataframe["participant_id"]
    subj_list = subj_list.sample(frac=1).reset_index(drop=True)
    if args.max_subj is not None:
        subj_list = subj_list.loc[: args.max_subj]

    w_size = 300  # Parameter TODO put somewhere else when factoring in fucntions
    fs = 500  # Parameter TODO put somewhere else when factoring in fucntions
    w_size = int(w_size * fs / 1000)

    bands_values = [[], []]
    sal_options = ["pos", "neg"] if args.saliency == "both" else [args.saliency]
    for sal_option in sal_options:
        for sub in subj_list:
            examples, targets = load_data(args.path, sub)
            if targets is None:
                continue
            print(sub)
            targets = np.array(targets)
            examples = np.array(examples)
            for targ in np.unique(targets):
                chan_data = Parallel(n_jobs=-1)(
                    delayed(compute_the_good_stuff)(
                        net,
                        trial,
                        y,
                        w_size,
                        fs,
                        use_windows=args.use_windows,
                        sal_option=sal_option,
                    )
                    for trial, y in zip(
                        examples[targets == targ], targets[targets == targ]
                    )
                )
                chan_data = [e for e in chan_data if e is not None]
                bands_values[targ] += chan_data
        print(
            f"used {len(bands_values[0])} image trials, and {len(bands_values[1])} sound trials."
        )
        for i, bv in enumerate(bands_values):
            np.save(name + f"_{LABELS[i]}.npy", bv)
