from collections.abc import Iterable
import numpy as np
import pandas as pd
import torch
import os
from joblib import Parallel, delayed, parallel_backend
from camcan.params import TIME_TRIAL_LENGTH
from camcan.utils import compute_psd
from camcan.parsing import parser
from camcan.network import create_net
from camcan.misc_functions import get_positive_negative_saliency, compute_sal_psd
from camcan.utils import load_checkpoint, cuda_check
from visu_filter_outputs import load_data


DEVICE = "cpu"
LABELS = ["image", "sound"]  # image is label 0 and sound label 1


if __name__ == "__main__":
    parser.add_argument(
        "--use-windows",
        action="store_true",
        help="wether or not to use saliency windows generated by guided backprop.",
    )
    parser.add_argument(
        "--topomaps",
        action="store_true",
        help="wether or not to generate topomaps for the spatial layer.",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Will generate all programmed visualizations.",
    )
    parser.add_argument(
        "--spectral",
        action="store_true",
        help="for topograd and backprop, if set will do everything in spectral domain after welch transform. if not set, temporal.",
    )
    parser.add_argument(
        "--backprop",
        action="store_true",
        help="wether or not to generate the backprop filter.",
    )
    parser.add_argument(
        "--topograd",
        action="store_true",
        help="wether or not to generate the topomaps of the guided backprop.",
    )
    parser.add_argument(
        "--outputs",
        action="store_true",
        help="wether or not to generate the outputs of the conv layers.",
    )
    parser.add_argument(
        "--saliency",
        default="pos",
        choices=["pos", "neg", "both"],
        type=str,
        help="chooses whether to use positive saliency, negative saliency or the sum of them",
    )
    args = parser.parse_args()

    suffixes = ""
    if args.batchnorm:
        suffixes += "_BN"
    if args.maxpool != 0:
        suffixes += f"_maxpool{args.maxpool}"

    fold = args.fold + 1
    name = f"{args.model_name}_{args.seed}_fold{fold}_{args.sensors}"
    suffixes = ""
    if args.net_option == "custom_net":
        if args.batchnorm:
            suffixes += "_BN"
        if args.maxpool != 0:
            suffixes += f"_maxpool{args.maxpool}"

        name += f"_dropout{args.dropout}_filter{args.filters}_nchan{args.nchan}_lin{args.linear}_depth{args.hlayers}"
        name += suffixes

    if args.feature == "bins":
        trial_length = 241
    if args.feature == "bands":
        trial_length = 5
    elif args.feature == "temporal":
        trial_length = TIME_TRIAL_LENGTH
    elif args.feature == "cov":
        # TODO
        pass
    elif args.feature == "cosp":
        # TODO
        pass

    if args.sensors == "MAG":
        n_channels = 102
    elif args.sensors == "GRAD":
        n_channels = 204
    elif args.sensors == "ALL":
        n_channels = 306

    if args.subclf:
        # TODO
        raise "not yet implemented for subclf"
    else:
        n_outputs = 2

    input_size = (n_channels // 102, 102, trial_length)
    model_filepath = os.path.join("../models/", name + ".pt")

    net = create_net(args.net_option, name, input_size, n_outputs, args)
    epoch, net_state, optimizer_state = load_checkpoint(model_filepath)
    net.load_state_dict(net_state)
    net.to(DEVICE)

    dataframe = pd.read_csv(f"{args.path}clean_participant_new.csv", index_col=0)
    subj_list = dataframe["participant_id"]
    subj_list = subj_list.sample(frac=1).reset_index(drop=True)
    if args.max_subj is not None:
        subj_list = subj_list.loc[: args.max_subj]

    w_size = 300  # Parameter TODO put somewhere else when factoring in fucntions
    fs = 500  # Parameter TODO put somewhere else when factoring in fucntions
    w_size = int(w_size * fs / 1000)

    bands_values = [[], []]
    sal_options = ["pos", "neg"] if args.saliency == "both" else [args.saliency]
    for sal_option in sal_options:
        for sub in subj_list:
            examples, targets = load_data(args.path, sub)
            if targets is None:
                continue
            print(sub)
            targets = np.array(targets)
            examples = np.array(examples)
            for targ in np.unique(targets):
                chan_data = Parallel(n_jobs=-1)(
                    delayed(compute_sal_psd)(
                        net,
                        trial,
                        y,
                        w_size,
                        fs,
                        use_windows=args.use_windows,
                        sal_option=sal_option,
                    )
                    for trial, y in zip(
                        examples[targets == targ], targets[targets == targ]
                    )
                )
                chan_data = [e for e in chan_data if e is not None]
                bands_values[targ] += chan_data
        print(
            f"used {len(bands_values[0])} image trials, and {len(bands_values[1])} sound trials."
        )
        for i, bv in enumerate(bands_values):
            np.save(name + f"_{LABELS[i]}.npy", bv)
