{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b87c1a-b92d-42d4-96f7-2ea1ad570435",
   "metadata": {},
   "source": [
    "## Train Network Basics\n",
    "\n",
    "## How to use the dataset class\n",
    "\n",
    "Loading a dataset requires the data to be in the correct format (see Prepare data tutorial). Just create the dataset object and use the load method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7900d693-e52e-44ec-8de9-e42bafb214de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/18/2024 08:35:40 AM Logging subjects and labels from /home/arthur/data/camcan/smt...\n",
      "10/18/2024 08:35:40 AM Found 20 subjects to load.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %I:%M:%S %p\",\n",
    ")\n",
    "\n",
    "from meegnet.dataloaders import ContinuousDataset\n",
    "\n",
    "data_path = \"/home/arthur/data/camcan/smt\"\n",
    "\n",
    "# use Dataset class for data that has already been cut into trials\n",
    "# else, use RestDataset with additional parameters of window and overlap to create trials.\n",
    "dataset = ContinuousDataset(\n",
    "    window = .8,\n",
    "    overlap = 0,\n",
    "    sfreq=500, # sampling frequency of 500 Hz\n",
    "    n_subjects=20, # only load 100 subjects\n",
    "    n_samples=10, # limit the number of samples for each subject to 100\n",
    "    sensortype=\"ALL\", # only use gradiometers\n",
    "    lso=True, # do not use leave subject oout for data splits\n",
    ")\n",
    "\n",
    "dataset.load(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4273d6-b892-4b46-8777-2ad824d2ac21",
   "metadata": {},
   "source": [
    "We have loaded 100 subjects of the resting-state dataset located in data_path. There are 100 examples per subject so 10000 data examples total. With only gradiometers selected with sensors=\"GRAD\", we only have 2 channels. The length of each time segment is 4 seconds at 200Hz which is why they are 800 time points of size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315df099-6a5f-41cd-b928-e35fa6a85545",
   "metadata": {},
   "source": [
    "## How to use the network class\n",
    "\n",
    "Create the model object instance of the Model class and then use the train method with the dataset previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1998d5d8-0457-4cc6-9f9e-b1dc535a34eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/18/2024 08:36:10 AM Creating DataLoaders...\n",
      "10/18/2024 08:36:10 AM Starting Training with:\n",
      "10/18/2024 08:36:10 AM batch size: 128\n",
      "10/18/2024 08:36:10 AM learning rate: 1e-05\n",
      "10/18/2024 08:36:10 AM patience: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGNet(\n",
      "  (feature_extraction): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(1, 64), stride=(1, 1), padding=(1, 32), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): DepthwiseConv2d(\n",
      "      (depthwise): Conv2d(16, 32, kernel_size=(102, 1), stride=(1, 1), groups=16, bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ELU(alpha=1.0)\n",
      "    (5): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): SeparableConv2d(\n",
      "      (depthwise): DepthwiseConv2d(\n",
      "        (depthwise): Conv2d(32, 32, kernel_size=(1, 16), stride=(1, 1), padding=(1, 8), groups=32, bias=False)\n",
      "      )\n",
      "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), padding=(1, 8), bias=False)\n",
      "    )\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ELU(alpha=1.0)\n",
      "    (10): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Flatten()\n",
      "  )\n",
      "  (classif): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/18/2024 08:36:21 AM Epoch: 1 // Batch 1/2 // loss = 0.71562\n",
      "10/18/2024 08:36:23 AM Epoch: 1 // Batch 2/2 // loss = 0.78837\n",
      "10/18/2024 08:36:38 AM Epoch: 1\n",
      "10/18/2024 08:36:38 AM  [LOSS] TRAIN 0.7540044474329745 / VALID 0.8416368411741818\n",
      "10/18/2024 08:36:38 AM  [ACC] TRAIN 0.48125 / VALID 0.30000001192092896\n",
      "10/18/2024 08:36:48 AM Epoch: 2 // Batch 1/2 // loss = 0.71293\n",
      "10/18/2024 08:36:51 AM Epoch: 2 // Batch 2/2 // loss = 0.75221\n",
      "10/18/2024 08:37:03 AM Epoch: 2\n",
      "10/18/2024 08:37:03 AM  [LOSS] TRAIN 0.7409208513169709 / VALID 0.8747682543030727\n",
      "10/18/2024 08:37:03 AM  [ACC] TRAIN 0.45 / VALID 0.20000000298023224\n",
      "10/18/2024 08:37:14 AM Epoch: 3 // Batch 1/2 // loss = 0.75706\n",
      "10/18/2024 08:37:16 AM Epoch: 3 // Batch 2/2 // loss = 0.70096\n",
      "10/18/2024 08:37:30 AM Epoch: 3\n",
      "10/18/2024 08:37:30 AM  [LOSS] TRAIN 0.7284259412796468 / VALID 0.7865380775675327\n",
      "10/18/2024 08:37:30 AM  [ACC] TRAIN 0.475 / VALID 0.3499999940395355\n",
      "10/18/2024 08:37:41 AM Epoch: 4 // Batch 1/2 // loss = 0.74296\n",
      "10/18/2024 08:37:43 AM Epoch: 4 // Batch 2/2 // loss = 0.69414\n",
      "10/18/2024 08:37:56 AM Epoch: 4\n",
      "10/18/2024 08:37:56 AM  [LOSS] TRAIN 0.7510948263000654 / VALID 0.7927498944856756\n",
      "10/18/2024 08:37:56 AM  [ACC] TRAIN 0.45 / VALID 0.30000001192092896\n",
      "10/18/2024 08:38:06 AM Epoch: 5 // Batch 1/2 // loss = 0.76587\n",
      "10/18/2024 08:38:09 AM Epoch: 5 // Batch 2/2 // loss = 0.78898\n",
      "10/18/2024 08:38:23 AM Epoch: 5\n",
      "10/18/2024 08:38:23 AM  [LOSS] TRAIN 0.7299095663364006 / VALID 0.7664702637613667\n",
      "10/18/2024 08:38:23 AM  [ACC] TRAIN 0.48125 / VALID 0.3499999940395355\n",
      "10/18/2024 08:38:33 AM Epoch: 6 // Batch 1/2 // loss = 0.73876\n",
      "10/18/2024 08:38:36 AM Epoch: 6 // Batch 2/2 // loss = 0.68641\n",
      "10/18/2024 08:38:49 AM Epoch: 6\n",
      "10/18/2024 08:38:49 AM  [LOSS] TRAIN 0.7253512572800739 / VALID 0.7859511962379713\n",
      "10/18/2024 08:38:49 AM  [ACC] TRAIN 0.525 / VALID 0.30000001192092896\n",
      "10/18/2024 08:38:59 AM Epoch: 7 // Batch 1/2 // loss = 0.69312\n",
      "10/18/2024 08:39:02 AM Epoch: 7 // Batch 2/2 // loss = 0.75885\n",
      "10/18/2024 08:39:16 AM Epoch: 7\n",
      "10/18/2024 08:39:16 AM  [LOSS] TRAIN 0.7395229912591047 / VALID 0.7303152524891414\n",
      "10/18/2024 08:39:16 AM  [ACC] TRAIN 0.5 / VALID 0.4000000059604645\n",
      "10/18/2024 08:39:26 AM Epoch: 8 // Batch 1/2 // loss = 0.72731\n",
      "10/18/2024 08:39:29 AM Epoch: 8 // Batch 2/2 // loss = 0.71848\n",
      "10/18/2024 08:39:42 AM Epoch: 8\n",
      "10/18/2024 08:39:42 AM  [LOSS] TRAIN 0.7163032065733166 / VALID 0.7822817156886772\n",
      "10/18/2024 08:39:42 AM  [ACC] TRAIN 0.49375 / VALID 0.5\n",
      "10/18/2024 08:39:52 AM Epoch: 9 // Batch 1/2 // loss = 0.73476\n",
      "10/18/2024 08:39:54 AM Epoch: 9 // Batch 2/2 // loss = 0.72024\n",
      "10/18/2024 08:40:07 AM Epoch: 9\n",
      "10/18/2024 08:40:07 AM  [LOSS] TRAIN 0.7138368960793062 / VALID 0.8000484057098418\n",
      "10/18/2024 08:40:07 AM  [ACC] TRAIN 0.46875 / VALID 0.30000001192092896\n",
      "10/18/2024 08:40:18 AM Epoch: 10 // Batch 1/2 // loss = 0.71463\n",
      "10/18/2024 08:40:20 AM Epoch: 10 // Batch 2/2 // loss = 0.71762\n",
      "10/18/2024 08:40:34 AM Epoch: 10\n",
      "10/18/2024 08:40:34 AM  [LOSS] TRAIN 0.745093217590333 / VALID 0.714035079144277\n",
      "10/18/2024 08:40:34 AM  [ACC] TRAIN 0.4375 / VALID 0.44999998807907104\n",
      "10/18/2024 08:40:45 AM Epoch: 11 // Batch 1/2 // loss = 0.72695\n",
      "10/18/2024 08:40:47 AM Epoch: 11 // Batch 2/2 // loss = 0.71836\n",
      "10/18/2024 08:41:00 AM Epoch: 11\n",
      "10/18/2024 08:41:00 AM  [LOSS] TRAIN 0.7032077361973397 / VALID 0.7988090662137765\n",
      "10/18/2024 08:41:00 AM  [ACC] TRAIN 0.49375 / VALID 0.30000001192092896\n",
      "10/18/2024 08:41:10 AM Epoch: 12 // Batch 1/2 // loss = 0.74288\n",
      "10/18/2024 08:41:13 AM Epoch: 12 // Batch 2/2 // loss = 0.68081\n",
      "10/18/2024 08:41:26 AM Epoch: 12\n",
      "10/18/2024 08:41:26 AM  [LOSS] TRAIN 0.7387376505830676 / VALID 0.7315110007770712\n",
      "10/18/2024 08:41:26 AM  [ACC] TRAIN 0.45 / VALID 0.4000000059604645\n",
      "10/18/2024 08:41:36 AM Epoch: 13 // Batch 1/2 // loss = 0.73502\n",
      "10/18/2024 08:41:39 AM Epoch: 13 // Batch 2/2 // loss = 0.71618\n",
      "10/18/2024 08:41:52 AM Epoch: 13\n",
      "10/18/2024 08:41:52 AM  [LOSS] TRAIN 0.7324431840220369 / VALID 0.752247342017954\n",
      "10/18/2024 08:41:52 AM  [ACC] TRAIN 0.4875 / VALID 0.4000000059604645\n",
      "10/18/2024 08:42:02 AM Epoch: 14 // Batch 1/2 // loss = 0.72519\n",
      "10/18/2024 08:42:05 AM Epoch: 14 // Batch 2/2 // loss = 0.75404\n",
      "10/18/2024 08:42:17 AM Epoch: 14\n",
      "10/18/2024 08:42:17 AM  [LOSS] TRAIN 0.757997307853365 / VALID 0.7862978944295185\n",
      "10/18/2024 08:42:17 AM  [ACC] TRAIN 0.44375 / VALID 0.30000001192092896\n",
      "10/18/2024 08:42:28 AM Epoch: 15 // Batch 1/2 // loss = 0.72307\n",
      "10/18/2024 08:42:30 AM Epoch: 15 // Batch 2/2 // loss = 0.80580\n",
      "10/18/2024 08:42:43 AM Epoch: 15\n",
      "10/18/2024 08:42:43 AM  [LOSS] TRAIN 0.7400326721491843 / VALID 0.7198375174883891\n",
      "10/18/2024 08:42:43 AM  [ACC] TRAIN 0.44375 / VALID 0.6000000238418579\n",
      "10/18/2024 08:42:54 AM Epoch: 16 // Batch 1/2 // loss = 0.71359\n",
      "10/18/2024 08:42:56 AM Epoch: 16 // Batch 2/2 // loss = 0.73314\n",
      "10/18/2024 08:43:09 AM Epoch: 16\n",
      "10/18/2024 08:43:09 AM  [LOSS] TRAIN 0.7053370455616901 / VALID 0.8700323261229833\n",
      "10/18/2024 08:43:09 AM  [ACC] TRAIN 0.5625 / VALID 0.20000000298023224\n",
      "10/18/2024 08:43:19 AM Epoch: 17 // Batch 1/2 // loss = 0.72089\n",
      "10/18/2024 08:43:22 AM Epoch: 17 // Batch 2/2 // loss = 0.71549\n",
      "10/18/2024 08:43:35 AM Epoch: 17\n",
      "10/18/2024 08:43:35 AM  [LOSS] TRAIN 0.7356418956932904 / VALID 0.7813994091675414\n",
      "10/18/2024 08:43:35 AM  [ACC] TRAIN 0.4125 / VALID 0.4000000059604645\n",
      "10/18/2024 08:43:45 AM Epoch: 18 // Batch 1/2 // loss = 0.74243\n",
      "10/18/2024 08:43:48 AM Epoch: 18 // Batch 2/2 // loss = 0.65522\n",
      "10/18/2024 08:44:01 AM Epoch: 18\n",
      "10/18/2024 08:44:01 AM  [LOSS] TRAIN 0.7171687730073204 / VALID 0.7871122965553826\n",
      "10/18/2024 08:44:01 AM  [ACC] TRAIN 0.50625 / VALID 0.3499999940395355\n",
      "10/18/2024 08:44:11 AM Epoch: 19 // Batch 1/2 // loss = 0.73510\n",
      "10/18/2024 08:44:14 AM Epoch: 19 // Batch 2/2 // loss = 0.69715\n",
      "10/18/2024 08:44:26 AM Epoch: 19\n",
      "10/18/2024 08:44:26 AM  [LOSS] TRAIN 0.7280480305713481 / VALID 0.7353390738591069\n",
      "10/18/2024 08:44:26 AM  [ACC] TRAIN 0.4875 / VALID 0.5\n",
      "10/18/2024 08:44:37 AM Epoch: 20 // Batch 1/2 // loss = 0.70793\n",
      "10/18/2024 08:44:39 AM Epoch: 20 // Batch 2/2 // loss = 0.73179\n",
      "10/18/2024 08:44:52 AM Epoch: 20\n",
      "10/18/2024 08:44:52 AM  [LOSS] TRAIN 0.730310513168231 / VALID 0.7543777721639819\n",
      "10/18/2024 08:44:52 AM  [ACC] TRAIN 0.48125 / VALID 0.3499999940395355\n",
      "10/18/2024 08:45:03 AM Epoch: 21 // Batch 1/2 // loss = 0.74062\n",
      "10/18/2024 08:45:05 AM Epoch: 21 // Batch 2/2 // loss = 0.67710\n",
      "10/18/2024 08:45:18 AM Epoch: 21\n",
      "10/18/2024 08:45:18 AM  [LOSS] TRAIN 0.7091995991211506 / VALID 0.7201689792695616\n",
      "10/18/2024 08:45:18 AM  [ACC] TRAIN 0.54375 / VALID 0.30000001192092896\n",
      "10/18/2024 08:45:28 AM Epoch: 22 // Batch 1/2 // loss = 0.73132\n",
      "10/18/2024 08:45:31 AM Epoch: 22 // Batch 2/2 // loss = 0.66897\n",
      "10/18/2024 08:45:44 AM Epoch: 22\n",
      "10/18/2024 08:45:44 AM  [LOSS] TRAIN 0.7319965961421184 / VALID 0.8242989357287609\n",
      "10/18/2024 08:45:44 AM  [ACC] TRAIN 0.50625 / VALID 0.3499999940395355\n",
      "10/18/2024 08:45:54 AM Epoch: 23 // Batch 1/2 // loss = 0.71481\n",
      "10/18/2024 08:45:57 AM Epoch: 23 // Batch 2/2 // loss = 0.68826\n",
      "10/18/2024 08:46:10 AM Epoch: 23\n",
      "10/18/2024 08:46:10 AM  [LOSS] TRAIN 0.7236138742612719 / VALID 0.7262680999873131\n",
      "10/18/2024 08:46:10 AM  [ACC] TRAIN 0.45625 / VALID 0.5\n",
      "10/18/2024 08:46:20 AM Epoch: 24 // Batch 1/2 // loss = 0.72178\n",
      "10/18/2024 08:46:23 AM Epoch: 24 // Batch 2/2 // loss = 0.64548\n",
      "10/18/2024 08:46:35 AM Epoch: 24\n",
      "10/18/2024 08:46:35 AM  [LOSS] TRAIN 0.7169925060451553 / VALID 0.7442306034780495\n",
      "10/18/2024 08:46:35 AM  [ACC] TRAIN 0.49375 / VALID 0.3499999940395355\n",
      "10/18/2024 08:46:46 AM Epoch: 25 // Batch 1/2 // loss = 0.72309\n",
      "10/18/2024 08:46:48 AM Epoch: 25 // Batch 2/2 // loss = 0.73215\n",
      "10/18/2024 08:47:03 AM Epoch: 25\n",
      "10/18/2024 08:47:03 AM  [LOSS] TRAIN 0.7051408104770676 / VALID 0.7083358098188958\n",
      "10/18/2024 08:47:03 AM  [ACC] TRAIN 0.5125 / VALID 0.4000000059604645\n",
      "10/18/2024 08:47:13 AM Epoch: 26 // Batch 1/2 // loss = 0.73244\n",
      "10/18/2024 08:47:16 AM Epoch: 26 // Batch 2/2 // loss = 0.77190\n",
      "10/18/2024 08:47:28 AM Epoch: 26\n",
      "10/18/2024 08:47:28 AM  [LOSS] TRAIN 0.7089046725902473 / VALID 0.7360169764132534\n",
      "10/18/2024 08:47:28 AM  [ACC] TRAIN 0.5375 / VALID 0.5\n",
      "10/18/2024 08:47:39 AM Epoch: 27 // Batch 1/2 // loss = 0.70617\n",
      "10/18/2024 08:47:41 AM Epoch: 27 // Batch 2/2 // loss = 0.77781\n",
      "10/18/2024 08:47:54 AM Epoch: 27\n",
      "10/18/2024 08:47:54 AM  [LOSS] TRAIN 0.7193922784702562 / VALID 0.8476672557671392\n",
      "10/18/2024 08:47:54 AM  [ACC] TRAIN 0.5125 / VALID 0.20000000298023224\n",
      "10/18/2024 08:48:05 AM Epoch: 28 // Batch 1/2 // loss = 0.69589\n",
      "10/18/2024 08:48:07 AM Epoch: 28 // Batch 2/2 // loss = 0.70746\n",
      "10/18/2024 08:48:20 AM Epoch: 28\n",
      "10/18/2024 08:48:20 AM  [LOSS] TRAIN 0.7001080150586764 / VALID 0.741007117880702\n",
      "10/18/2024 08:48:20 AM  [ACC] TRAIN 0.5125 / VALID 0.4000000059604645\n",
      "10/18/2024 08:48:30 AM Epoch: 29 // Batch 1/2 // loss = 0.72379\n",
      "10/18/2024 08:48:33 AM Epoch: 29 // Batch 2/2 // loss = 0.72835\n",
      "10/18/2024 08:48:46 AM Epoch: 29\n",
      "10/18/2024 08:48:46 AM  [LOSS] TRAIN 0.7132964369139239 / VALID 0.7789284382215144\n",
      "10/18/2024 08:48:46 AM  [ACC] TRAIN 0.50625 / VALID 0.25\n",
      "10/18/2024 08:48:56 AM Epoch: 30 // Batch 1/2 // loss = 0.69492\n",
      "10/18/2024 08:48:59 AM Epoch: 30 // Batch 2/2 // loss = 0.67384\n",
      "10/18/2024 08:49:12 AM Epoch: 30\n",
      "10/18/2024 08:49:12 AM  [LOSS] TRAIN 0.7035393844216339 / VALID 0.7835258472572424\n",
      "10/18/2024 08:49:12 AM  [ACC] TRAIN 0.55 / VALID 0.4000000059604645\n",
      "10/18/2024 08:49:22 AM Epoch: 31 // Batch 1/2 // loss = 0.73909\n",
      "10/18/2024 08:49:25 AM Epoch: 31 // Batch 2/2 // loss = 0.68860\n",
      "10/18/2024 08:49:39 AM Epoch: 31\n",
      "10/18/2024 08:49:39 AM  [LOSS] TRAIN 0.7268568684600158 / VALID 0.7041009148030754\n",
      "10/18/2024 08:49:39 AM  [ACC] TRAIN 0.4625 / VALID 0.5\n",
      "10/18/2024 08:49:49 AM Epoch: 32 // Batch 1/2 // loss = 0.70031\n",
      "10/18/2024 08:49:52 AM Epoch: 32 // Batch 2/2 // loss = 0.69792\n",
      "10/18/2024 08:50:05 AM Epoch: 32\n",
      "10/18/2024 08:50:05 AM  [LOSS] TRAIN 0.7135573113040522 / VALID 0.7102644109283134\n",
      "10/18/2024 08:50:05 AM  [ACC] TRAIN 0.5125 / VALID 0.5\n",
      "10/18/2024 08:50:15 AM Epoch: 33 // Batch 1/2 // loss = 0.71768\n",
      "10/18/2024 08:50:18 AM Epoch: 33 // Batch 2/2 // loss = 0.73724\n",
      "10/18/2024 08:50:30 AM Epoch: 33\n",
      "10/18/2024 08:50:30 AM  [LOSS] TRAIN 0.6940594670626673 / VALID 0.7224486223607767\n",
      "10/18/2024 08:50:30 AM  [ACC] TRAIN 0.51875 / VALID 0.4000000059604645\n",
      "10/18/2024 08:50:41 AM Epoch: 34 // Batch 1/2 // loss = 0.71132\n",
      "10/18/2024 08:50:43 AM Epoch: 34 // Batch 2/2 // loss = 0.71033\n",
      "10/18/2024 08:50:56 AM Epoch: 34\n",
      "10/18/2024 08:50:56 AM  [LOSS] TRAIN 0.6666613921619715 / VALID 0.7588846912870375\n",
      "10/18/2024 08:50:56 AM  [ACC] TRAIN 0.58125 / VALID 0.30000001192092896\n",
      "10/18/2024 08:51:07 AM Epoch: 35 // Batch 1/2 // loss = 0.69338\n",
      "10/18/2024 08:51:09 AM Epoch: 35 // Batch 2/2 // loss = 0.68643\n",
      "10/18/2024 08:51:23 AM Epoch: 35\n",
      "10/18/2024 08:51:23 AM  [LOSS] TRAIN 0.708972824719823 / VALID 0.6749334111931341\n",
      "10/18/2024 08:51:23 AM  [ACC] TRAIN 0.46875 / VALID 0.6000000238418579\n",
      "10/18/2024 08:51:34 AM Epoch: 36 // Batch 1/2 // loss = 0.72556\n",
      "10/18/2024 08:51:36 AM Epoch: 36 // Batch 2/2 // loss = 0.68710\n",
      "10/18/2024 08:51:49 AM Epoch: 36\n",
      "10/18/2024 08:51:49 AM  [LOSS] TRAIN 0.6824172408273332 / VALID 0.7650381078486311\n",
      "10/18/2024 08:51:49 AM  [ACC] TRAIN 0.58125 / VALID 0.3499999940395355\n",
      "10/18/2024 08:52:00 AM Epoch: 37 // Batch 1/2 // loss = 0.70015\n",
      "10/18/2024 08:52:02 AM Epoch: 37 // Batch 2/2 // loss = 0.69946\n",
      "10/18/2024 08:52:15 AM Epoch: 37\n",
      "10/18/2024 08:52:15 AM  [LOSS] TRAIN 0.7042470214745381 / VALID 0.7827091235743298\n",
      "10/18/2024 08:52:15 AM  [ACC] TRAIN 0.5375 / VALID 0.3499999940395355\n",
      "10/18/2024 08:52:25 AM Epoch: 38 // Batch 1/2 // loss = 0.72133\n",
      "10/18/2024 08:52:28 AM Epoch: 38 // Batch 2/2 // loss = 0.71192\n",
      "10/18/2024 08:52:41 AM Epoch: 38\n",
      "10/18/2024 08:52:41 AM  [LOSS] TRAIN 0.7036459848019763 / VALID 0.6978516977756135\n",
      "10/18/2024 08:52:41 AM  [ACC] TRAIN 0.5125 / VALID 0.550000011920929\n",
      "10/18/2024 08:52:51 AM Epoch: 39 // Batch 1/2 // loss = 0.71802\n",
      "10/18/2024 08:52:54 AM Epoch: 39 // Batch 2/2 // loss = 0.69918\n",
      "10/18/2024 08:53:08 AM Epoch: 39\n",
      "10/18/2024 08:53:08 AM  [LOSS] TRAIN 0.708125358748416 / VALID 0.6706468888670789\n",
      "10/18/2024 08:53:08 AM  [ACC] TRAIN 0.51875 / VALID 0.550000011920929\n",
      "10/18/2024 08:53:18 AM Epoch: 40 // Batch 1/2 // loss = 0.71590\n",
      "10/18/2024 08:53:21 AM Epoch: 40 // Batch 2/2 // loss = 0.81042\n",
      "10/18/2024 08:53:34 AM Epoch: 40\n",
      "10/18/2024 08:53:34 AM  [LOSS] TRAIN 0.7228354671590752 / VALID 0.7725686907496628\n",
      "10/18/2024 08:53:34 AM  [ACC] TRAIN 0.51875 / VALID 0.44999998807907104\n",
      "10/18/2024 08:53:44 AM Epoch: 41 // Batch 1/2 // loss = 0.71032\n",
      "10/18/2024 08:53:47 AM Epoch: 41 // Batch 2/2 // loss = 0.71213\n",
      "10/18/2024 08:54:00 AM Epoch: 41\n",
      "10/18/2024 08:54:00 AM  [LOSS] TRAIN 0.7104760828874661 / VALID 0.8440629947104534\n",
      "10/18/2024 08:54:00 AM  [ACC] TRAIN 0.49375 / VALID 0.25\n",
      "10/18/2024 08:54:10 AM Epoch: 42 // Batch 1/2 // loss = 0.69022\n",
      "10/18/2024 08:54:13 AM Epoch: 42 // Batch 2/2 // loss = 0.71226\n",
      "10/18/2024 08:54:25 AM Epoch: 42\n",
      "10/18/2024 08:54:25 AM  [LOSS] TRAIN 0.6972596854356873 / VALID 0.6779049341280434\n",
      "10/18/2024 08:54:25 AM  [ACC] TRAIN 0.525 / VALID 0.6499999761581421\n",
      "10/18/2024 08:54:36 AM Epoch: 43 // Batch 1/2 // loss = 0.68142\n",
      "10/18/2024 08:54:38 AM Epoch: 43 // Batch 2/2 // loss = 0.72992\n",
      "10/18/2024 08:54:51 AM Epoch: 43\n",
      "10/18/2024 08:54:51 AM  [LOSS] TRAIN 0.7291114681695732 / VALID 0.8262428641426842\n",
      "10/18/2024 08:54:51 AM  [ACC] TRAIN 0.4375 / VALID 0.25\n",
      "10/18/2024 08:55:02 AM Epoch: 44 // Batch 1/2 // loss = 0.70837\n",
      "10/18/2024 08:55:04 AM Epoch: 44 // Batch 2/2 // loss = 0.69320\n",
      "10/18/2024 08:55:17 AM Epoch: 44\n",
      "10/18/2024 08:55:17 AM  [LOSS] TRAIN 0.7039070403646829 / VALID 0.7403241846028256\n",
      "10/18/2024 08:55:17 AM  [ACC] TRAIN 0.46875 / VALID 0.5\n",
      "10/18/2024 08:55:27 AM Epoch: 45 // Batch 1/2 // loss = 0.70371\n",
      "10/18/2024 08:55:30 AM Epoch: 45 // Batch 2/2 // loss = 0.71380\n",
      "10/18/2024 08:55:43 AM Epoch: 45\n",
      "10/18/2024 08:55:43 AM  [LOSS] TRAIN 0.6786972988832373 / VALID 0.7829058876180671\n",
      "10/18/2024 08:55:43 AM  [ACC] TRAIN 0.60625 / VALID 0.25\n",
      "10/18/2024 08:55:53 AM Epoch: 46 // Batch 1/2 // loss = 0.69713\n",
      "10/18/2024 08:55:56 AM Epoch: 46 // Batch 2/2 // loss = 0.70003\n",
      "10/18/2024 08:56:10 AM Epoch: 46\n",
      "10/18/2024 08:56:10 AM  [LOSS] TRAIN 0.716514469250835 / VALID 0.6656966504984195\n",
      "10/18/2024 08:56:10 AM  [ACC] TRAIN 0.46875 / VALID 0.550000011920929\n",
      "10/18/2024 08:56:20 AM Epoch: 47 // Batch 1/2 // loss = 0.71063\n",
      "10/18/2024 08:56:23 AM Epoch: 47 // Batch 2/2 // loss = 0.67784\n",
      "10/18/2024 08:56:37 AM Epoch: 47\n",
      "10/18/2024 08:56:37 AM  [LOSS] TRAIN 0.7269677237061237 / VALID 0.6538133064348595\n",
      "10/18/2024 08:56:37 AM  [ACC] TRAIN 0.46875 / VALID 0.6000000238418579\n",
      "10/18/2024 08:56:47 AM Epoch: 48 // Batch 1/2 // loss = 0.72456\n",
      "10/18/2024 08:56:50 AM Epoch: 48 // Batch 2/2 // loss = 0.73812\n",
      "10/18/2024 08:57:03 AM Epoch: 48\n",
      "10/18/2024 08:57:03 AM  [LOSS] TRAIN 0.6990533958884317 / VALID 0.729586634100764\n",
      "10/18/2024 08:57:03 AM  [ACC] TRAIN 0.5125 / VALID 0.44999998807907104\n",
      "10/18/2024 08:57:13 AM Epoch: 49 // Batch 1/2 // loss = 0.70529\n",
      "10/18/2024 08:57:16 AM Epoch: 49 // Batch 2/2 // loss = 0.73373\n",
      "10/18/2024 08:57:28 AM Epoch: 49\n",
      "10/18/2024 08:57:28 AM  [LOSS] TRAIN 0.6862487193911788 / VALID 0.7360203840678817\n",
      "10/18/2024 08:57:29 AM  [ACC] TRAIN 0.6 / VALID 0.5\n",
      "10/18/2024 08:57:39 AM Epoch: 50 // Batch 1/2 // loss = 0.69736\n",
      "10/18/2024 08:57:41 AM Epoch: 50 // Batch 2/2 // loss = 0.71791\n",
      "10/18/2024 08:57:54 AM Epoch: 50\n",
      "10/18/2024 08:57:54 AM  [LOSS] TRAIN 0.6896639351612415 / VALID 0.6596255443479907\n",
      "10/18/2024 08:57:54 AM  [ACC] TRAIN 0.5375 / VALID 0.699999988079071\n",
      "10/18/2024 08:58:05 AM Epoch: 51 // Batch 1/2 // loss = 0.74495\n",
      "10/18/2024 08:58:07 AM Epoch: 51 // Batch 2/2 // loss = 0.69293\n",
      "10/18/2024 08:58:20 AM Epoch: 51\n",
      "10/18/2024 08:58:20 AM  [LOSS] TRAIN 0.7231388513477538 / VALID 0.6656630098392146\n",
      "10/18/2024 08:58:20 AM  [ACC] TRAIN 0.475 / VALID 0.6000000238418579\n",
      "10/18/2024 08:58:31 AM Epoch: 52 // Batch 1/2 // loss = 0.66605\n",
      "10/18/2024 08:58:33 AM Epoch: 52 // Batch 2/2 // loss = 0.66383\n",
      "10/18/2024 08:58:46 AM Epoch: 52\n",
      "10/18/2024 08:58:46 AM  [LOSS] TRAIN 0.6972481971529317 / VALID 0.7373132926773385\n",
      "10/18/2024 08:58:46 AM  [ACC] TRAIN 0.55 / VALID 0.5\n",
      "10/18/2024 08:58:56 AM Epoch: 53 // Batch 1/2 // loss = 0.71590\n",
      "10/18/2024 08:58:59 AM Epoch: 53 // Batch 2/2 // loss = 0.73046\n",
      "10/18/2024 08:59:12 AM Epoch: 53\n",
      "10/18/2024 08:59:12 AM  [LOSS] TRAIN 0.6898075653429279 / VALID 0.7706905298876172\n",
      "10/18/2024 08:59:12 AM  [ACC] TRAIN 0.5625 / VALID 0.4000000059604645\n",
      "10/18/2024 08:59:22 AM Epoch: 54 // Batch 1/2 // loss = 0.73751\n",
      "10/18/2024 08:59:25 AM Epoch: 54 // Batch 2/2 // loss = 0.71368\n",
      "10/18/2024 08:59:38 AM Epoch: 54\n",
      "10/18/2024 08:59:38 AM  [LOSS] TRAIN 0.7255255762430164 / VALID 0.7409695911191928\n",
      "10/18/2024 08:59:38 AM  [ACC] TRAIN 0.4875 / VALID 0.5\n",
      "10/18/2024 08:59:48 AM Epoch: 55 // Batch 1/2 // loss = 0.70830\n",
      "10/18/2024 08:59:51 AM Epoch: 55 // Batch 2/2 // loss = 0.64881\n",
      "10/18/2024 09:00:03 AM Epoch: 55\n",
      "10/18/2024 09:00:03 AM  [LOSS] TRAIN 0.6863188078040536 / VALID 0.702035162868354\n",
      "10/18/2024 09:00:03 AM  [ACC] TRAIN 0.575 / VALID 0.550000011920929\n",
      "10/18/2024 09:00:14 AM Epoch: 56 // Batch 1/2 // loss = 0.69210\n",
      "10/18/2024 09:00:16 AM Epoch: 56 // Batch 2/2 // loss = 0.72032\n",
      "10/18/2024 09:00:29 AM Epoch: 56\n",
      "10/18/2024 09:00:29 AM  [LOSS] TRAIN 0.7217696793601018 / VALID 0.7293311466108656\n",
      "10/18/2024 09:00:29 AM  [ACC] TRAIN 0.50625 / VALID 0.4000000059604645\n",
      "10/18/2024 09:00:40 AM Epoch: 57 // Batch 1/2 // loss = 0.67574\n",
      "10/18/2024 09:00:42 AM Epoch: 57 // Batch 2/2 // loss = 0.73395\n",
      "10/18/2024 09:00:55 AM Epoch: 57\n",
      "10/18/2024 09:00:55 AM  [LOSS] TRAIN 0.6922135363194551 / VALID 0.7507083997183577\n",
      "10/18/2024 09:00:55 AM  [ACC] TRAIN 0.5625 / VALID 0.5\n",
      "10/18/2024 09:01:05 AM Epoch: 58 // Batch 1/2 // loss = 0.71832\n",
      "10/18/2024 09:01:08 AM Epoch: 58 // Batch 2/2 // loss = 0.72408\n",
      "10/18/2024 09:01:21 AM Epoch: 58\n",
      "10/18/2024 09:01:21 AM  [LOSS] TRAIN 0.7176420366793501 / VALID 0.7605916005045638\n",
      "10/18/2024 09:01:21 AM  [ACC] TRAIN 0.44375 / VALID 0.4000000059604645\n",
      "10/18/2024 09:01:31 AM Epoch: 59 // Batch 1/2 // loss = 0.68636\n",
      "10/18/2024 09:01:34 AM Epoch: 59 // Batch 2/2 // loss = 0.72569\n",
      "10/18/2024 09:01:47 AM Epoch: 59\n",
      "10/18/2024 09:01:47 AM  [LOSS] TRAIN 0.7120811305470147 / VALID 0.717974098284782\n",
      "10/18/2024 09:01:47 AM  [ACC] TRAIN 0.5 / VALID 0.5\n",
      "10/18/2024 09:01:57 AM Epoch: 60 // Batch 1/2 // loss = 0.67722\n",
      "10/18/2024 09:02:00 AM Epoch: 60 // Batch 2/2 // loss = 0.71157\n",
      "10/18/2024 09:02:13 AM Epoch: 60\n",
      "10/18/2024 09:02:13 AM  [LOSS] TRAIN 0.7065107472099965 / VALID 0.683262485378912\n",
      "10/18/2024 09:02:13 AM  [ACC] TRAIN 0.51875 / VALID 0.550000011920929\n",
      "10/18/2024 09:02:23 AM Epoch: 61 // Batch 1/2 // loss = 0.70272\n",
      "10/18/2024 09:02:25 AM Epoch: 61 // Batch 2/2 // loss = 0.69105\n",
      "10/18/2024 09:02:38 AM Epoch: 61\n",
      "10/18/2024 09:02:38 AM  [LOSS] TRAIN 0.6927214065448349 / VALID 0.6760646266653015\n",
      "10/18/2024 09:02:38 AM  [ACC] TRAIN 0.55625 / VALID 0.6499999761581421\n",
      "10/18/2024 09:02:49 AM Epoch: 62 // Batch 1/2 // loss = 0.69848\n",
      "10/18/2024 09:02:51 AM Epoch: 62 // Batch 2/2 // loss = 0.73863\n",
      "10/18/2024 09:03:04 AM Epoch: 62\n",
      "10/18/2024 09:03:04 AM  [LOSS] TRAIN 0.7003856816449148 / VALID 0.708755324552919\n",
      "10/18/2024 09:03:04 AM  [ACC] TRAIN 0.4875 / VALID 0.6000000238418579\n",
      "10/18/2024 09:03:15 AM Epoch: 63 // Batch 1/2 // loss = 0.70204\n",
      "10/18/2024 09:03:17 AM Epoch: 63 // Batch 2/2 // loss = 0.74207\n",
      "10/18/2024 09:03:31 AM Epoch: 63\n",
      "10/18/2024 09:03:31 AM  [LOSS] TRAIN 0.7174396590814982 / VALID 0.6303082029121929\n",
      "10/18/2024 09:03:31 AM  [ACC] TRAIN 0.49375 / VALID 0.699999988079071\n",
      "10/18/2024 09:03:42 AM Epoch: 64 // Batch 1/2 // loss = 0.69662\n",
      "10/18/2024 09:03:44 AM Epoch: 64 // Batch 2/2 // loss = 0.73286\n",
      "10/18/2024 09:03:57 AM Epoch: 64\n",
      "10/18/2024 09:03:57 AM  [LOSS] TRAIN 0.6787146076854753 / VALID 0.7321003510728161\n",
      "10/18/2024 09:03:57 AM  [ACC] TRAIN 0.60625 / VALID 0.44999998807907104\n",
      "10/18/2024 09:04:08 AM Epoch: 65 // Batch 1/2 // loss = 0.67689\n",
      "10/18/2024 09:04:10 AM Epoch: 65 // Batch 2/2 // loss = 0.69312\n",
      "10/18/2024 09:04:23 AM Epoch: 65\n",
      "10/18/2024 09:04:23 AM  [LOSS] TRAIN 0.6865072129161798 / VALID 0.6899866605247597\n",
      "10/18/2024 09:04:23 AM  [ACC] TRAIN 0.55 / VALID 0.550000011920929\n",
      "10/18/2024 09:04:33 AM Epoch: 66 // Batch 1/2 // loss = 0.68916\n",
      "10/18/2024 09:04:36 AM Epoch: 66 // Batch 2/2 // loss = 0.67860\n",
      "10/18/2024 09:04:49 AM Epoch: 66\n",
      "10/18/2024 09:04:49 AM  [LOSS] TRAIN 0.6972113849696482 / VALID 0.7891421056922112\n",
      "10/18/2024 09:04:49 AM  [ACC] TRAIN 0.5125 / VALID 0.30000001192092896\n",
      "10/18/2024 09:04:59 AM Epoch: 67 // Batch 1/2 // loss = 0.73086\n",
      "10/18/2024 09:05:02 AM Epoch: 67 // Batch 2/2 // loss = 0.67273\n",
      "10/18/2024 09:05:15 AM Epoch: 67\n",
      "10/18/2024 09:05:15 AM  [LOSS] TRAIN 0.684004173447353 / VALID 0.7687291087349474\n",
      "10/18/2024 09:05:15 AM  [ACC] TRAIN 0.5625 / VALID 0.4000000059604645\n",
      "10/18/2024 09:05:25 AM Epoch: 68 // Batch 1/2 // loss = 0.69422\n",
      "10/18/2024 09:05:28 AM Epoch: 68 // Batch 2/2 // loss = 0.66643\n",
      "10/18/2024 09:05:40 AM Epoch: 68\n",
      "10/18/2024 09:05:40 AM  [LOSS] TRAIN 0.7166207427499462 / VALID 0.6901325489067054\n",
      "10/18/2024 09:05:40 AM  [ACC] TRAIN 0.51875 / VALID 0.5\n",
      "10/18/2024 09:05:51 AM Epoch: 69 // Batch 1/2 // loss = 0.72858\n",
      "10/18/2024 09:05:53 AM Epoch: 69 // Batch 2/2 // loss = 0.66993\n",
      "10/18/2024 09:06:06 AM Epoch: 69\n",
      "10/18/2024 09:06:06 AM  [LOSS] TRAIN 0.6823601237384063 / VALID 0.6941861854577553\n",
      "10/18/2024 09:06:06 AM  [ACC] TRAIN 0.575 / VALID 0.550000011920929\n",
      "10/18/2024 09:06:17 AM Epoch: 70 // Batch 1/2 // loss = 0.69867\n",
      "10/18/2024 09:06:19 AM Epoch: 70 // Batch 2/2 // loss = 0.69470\n",
      "10/18/2024 09:06:32 AM Epoch: 70\n",
      "10/18/2024 09:06:32 AM  [LOSS] TRAIN 0.703887186687443 / VALID 0.7360335059994666\n",
      "10/18/2024 09:06:32 AM  [ACC] TRAIN 0.54375 / VALID 0.30000001192092896\n",
      "10/18/2024 09:06:43 AM Epoch: 71 // Batch 1/2 // loss = 0.69507\n",
      "10/18/2024 09:06:45 AM Epoch: 71 // Batch 2/2 // loss = 0.70218\n",
      "10/18/2024 09:06:58 AM Epoch: 71\n",
      "10/18/2024 09:06:58 AM  [LOSS] TRAIN 0.709770357433251 / VALID 0.7919827911189328\n",
      "10/18/2024 09:06:58 AM  [ACC] TRAIN 0.51875 / VALID 0.4000000059604645\n",
      "10/18/2024 09:07:08 AM Epoch: 72 // Batch 1/2 // loss = 0.67672\n",
      "10/18/2024 09:07:11 AM Epoch: 72 // Batch 2/2 // loss = 0.71011\n",
      "10/18/2024 09:07:24 AM Epoch: 72\n",
      "10/18/2024 09:07:24 AM  [LOSS] TRAIN 0.6868380005670923 / VALID 0.7195240261763773\n",
      "10/18/2024 09:07:24 AM  [ACC] TRAIN 0.58125 / VALID 0.6499999761581421\n",
      "10/18/2024 09:07:34 AM Epoch: 73 // Batch 1/2 // loss = 0.71533\n",
      "10/18/2024 09:07:37 AM Epoch: 73 // Batch 2/2 // loss = 0.75402\n",
      "10/18/2024 09:07:50 AM Epoch: 73\n",
      "10/18/2024 09:07:50 AM  [LOSS] TRAIN 0.6857456169302039 / VALID 0.73853065764862\n",
      "10/18/2024 09:07:50 AM  [ACC] TRAIN 0.61875 / VALID 0.5\n",
      "10/18/2024 09:08:00 AM Epoch: 74 // Batch 1/2 // loss = 0.69712\n",
      "10/18/2024 09:08:03 AM Epoch: 74 // Batch 2/2 // loss = 0.74687\n",
      "10/18/2024 09:08:17 AM Epoch: 74\n",
      "10/18/2024 09:08:17 AM  [LOSS] TRAIN 0.6973946910568156 / VALID 0.5783885482445508\n",
      "10/18/2024 09:08:17 AM  [ACC] TRAIN 0.55 / VALID 0.8500000238418579\n",
      "10/18/2024 09:08:27 AM Epoch: 75 // Batch 1/2 // loss = 0.67330\n",
      "10/18/2024 09:08:30 AM Epoch: 75 // Batch 2/2 // loss = 0.74026\n",
      "10/18/2024 09:08:43 AM Epoch: 75\n",
      "10/18/2024 09:08:43 AM  [LOSS] TRAIN 0.7057941774673306 / VALID 0.6329575444421962\n",
      "10/18/2024 09:08:43 AM  [ACC] TRAIN 0.51875 / VALID 0.6499999761581421\n",
      "10/18/2024 09:08:53 AM Epoch: 76 // Batch 1/2 // loss = 0.67135\n",
      "10/18/2024 09:08:55 AM Epoch: 76 // Batch 2/2 // loss = 0.73359\n",
      "10/18/2024 09:09:08 AM Epoch: 76\n",
      "10/18/2024 09:09:08 AM  [LOSS] TRAIN 0.6946187253550302 / VALID 0.7592568798172491\n",
      "10/18/2024 09:09:08 AM  [ACC] TRAIN 0.58125 / VALID 0.4000000059604645\n",
      "10/18/2024 09:09:19 AM Epoch: 77 // Batch 1/2 // loss = 0.67053\n",
      "10/18/2024 09:09:21 AM Epoch: 77 // Batch 2/2 // loss = 0.70018\n",
      "10/18/2024 09:09:34 AM Epoch: 77\n",
      "10/18/2024 09:09:34 AM  [LOSS] TRAIN 0.7210026419460565 / VALID 0.6878250708725607\n",
      "10/18/2024 09:09:34 AM  [ACC] TRAIN 0.525 / VALID 0.6000000238418579\n",
      "10/18/2024 09:09:45 AM Epoch: 78 // Batch 1/2 // loss = 0.69271\n",
      "10/18/2024 09:09:47 AM Epoch: 78 // Batch 2/2 // loss = 0.68548\n",
      "10/18/2024 09:10:00 AM Epoch: 78\n",
      "10/18/2024 09:10:00 AM  [LOSS] TRAIN 0.6919498963933945 / VALID 0.7050638138945555\n",
      "10/18/2024 09:10:00 AM  [ACC] TRAIN 0.5 / VALID 0.5\n",
      "10/18/2024 09:10:10 AM Epoch: 79 // Batch 1/2 // loss = 0.70370\n",
      "10/18/2024 09:10:13 AM Epoch: 79 // Batch 2/2 // loss = 0.64729\n",
      "10/18/2024 09:10:26 AM Epoch: 79\n",
      "10/18/2024 09:10:26 AM  [LOSS] TRAIN 0.6893921224126849 / VALID 0.6763922800539006\n",
      "10/18/2024 09:10:26 AM  [ACC] TRAIN 0.5375 / VALID 0.6000000238418579\n",
      "10/18/2024 09:10:36 AM Epoch: 80 // Batch 1/2 // loss = 0.67472\n",
      "10/18/2024 09:10:39 AM Epoch: 80 // Batch 2/2 // loss = 0.72233\n",
      "10/18/2024 09:10:52 AM Epoch: 80\n",
      "10/18/2024 09:10:52 AM  [LOSS] TRAIN 0.6877679703727058 / VALID 0.7535273505583208\n",
      "10/18/2024 09:10:52 AM  [ACC] TRAIN 0.5 / VALID 0.30000001192092896\n",
      "10/18/2024 09:11:02 AM Epoch: 81 // Batch 1/2 // loss = 0.66857\n",
      "10/18/2024 09:11:05 AM Epoch: 81 // Batch 2/2 // loss = 0.77663\n",
      "10/18/2024 09:11:17 AM Epoch: 81\n",
      "10/18/2024 09:11:17 AM  [LOSS] TRAIN 0.6915634198288425 / VALID 0.7123741389919322\n",
      "10/18/2024 09:11:17 AM  [ACC] TRAIN 0.55625 / VALID 0.5\n",
      "10/18/2024 09:11:28 AM Epoch: 82 // Batch 1/2 // loss = 0.70046\n",
      "10/18/2024 09:11:30 AM Epoch: 82 // Batch 2/2 // loss = 0.71096\n",
      "10/18/2024 09:11:43 AM Epoch: 82\n",
      "10/18/2024 09:11:43 AM  [LOSS] TRAIN 0.6964804977983862 / VALID 0.7208973308523728\n",
      "10/18/2024 09:11:43 AM  [ACC] TRAIN 0.55 / VALID 0.5\n",
      "10/18/2024 09:11:54 AM Epoch: 83 // Batch 1/2 // loss = 0.69168\n",
      "10/18/2024 09:11:56 AM Epoch: 83 // Batch 2/2 // loss = 0.70766\n",
      "10/18/2024 09:12:09 AM Epoch: 83\n",
      "10/18/2024 09:12:09 AM  [LOSS] TRAIN 0.6899888375203557 / VALID 0.7139285978943068\n",
      "10/18/2024 09:12:09 AM  [ACC] TRAIN 0.58125 / VALID 0.44999998807907104\n",
      "10/18/2024 09:12:20 AM Epoch: 84 // Batch 1/2 // loss = 0.71413\n",
      "10/18/2024 09:12:22 AM Epoch: 84 // Batch 2/2 // loss = 0.67798\n",
      "10/18/2024 09:12:35 AM Epoch: 84\n",
      "10/18/2024 09:12:35 AM  [LOSS] TRAIN 0.72190715067708 / VALID 0.7041804547582823\n",
      "10/18/2024 09:12:35 AM  [ACC] TRAIN 0.4625 / VALID 0.5\n",
      "10/18/2024 09:12:45 AM Epoch: 85 // Batch 1/2 // loss = 0.67344\n",
      "10/18/2024 09:12:48 AM Epoch: 85 // Batch 2/2 // loss = 0.69863\n",
      "10/18/2024 09:13:01 AM Epoch: 85\n",
      "10/18/2024 09:13:01 AM  [LOSS] TRAIN 0.6966438801876392 / VALID 0.6541769546389447\n",
      "10/18/2024 09:13:01 AM  [ACC] TRAIN 0.53125 / VALID 0.75\n",
      "10/18/2024 09:13:11 AM Epoch: 86 // Batch 1/2 // loss = 0.66821\n",
      "10/18/2024 09:13:14 AM Epoch: 86 // Batch 2/2 // loss = 0.59353\n",
      "10/18/2024 09:13:27 AM Epoch: 86\n",
      "10/18/2024 09:13:27 AM  [LOSS] TRAIN 0.6804760514900281 / VALID 0.7163073043398839\n",
      "10/18/2024 09:13:27 AM  [ACC] TRAIN 0.56875 / VALID 0.5\n",
      "10/18/2024 09:13:37 AM Epoch: 87 // Batch 1/2 // loss = 0.68774\n",
      "10/18/2024 09:13:40 AM Epoch: 87 // Batch 2/2 // loss = 0.66551\n",
      "10/18/2024 09:13:52 AM Epoch: 87\n",
      "10/18/2024 09:13:52 AM  [LOSS] TRAIN 0.693619311067803 / VALID 0.7550525977693577\n",
      "10/18/2024 09:13:52 AM  [ACC] TRAIN 0.55 / VALID 0.5\n",
      "10/18/2024 09:14:03 AM Epoch: 88 // Batch 1/2 // loss = 0.70602\n",
      "10/18/2024 09:14:05 AM Epoch: 88 // Batch 2/2 // loss = 0.67354\n",
      "10/18/2024 09:14:18 AM Epoch: 88\n",
      "10/18/2024 09:14:18 AM  [LOSS] TRAIN 0.689455360865839 / VALID 0.6807845178206755\n",
      "10/18/2024 09:14:18 AM  [ACC] TRAIN 0.55625 / VALID 0.6000000238418579\n",
      "10/18/2024 09:14:29 AM Epoch: 89 // Batch 1/2 // loss = 0.69777\n",
      "10/18/2024 09:14:31 AM Epoch: 89 // Batch 2/2 // loss = 0.66640\n",
      "10/18/2024 09:14:44 AM Epoch: 89\n",
      "10/18/2024 09:14:44 AM  [LOSS] TRAIN 0.7148686104712101 / VALID 0.6699494682760112\n",
      "10/18/2024 09:14:44 AM  [ACC] TRAIN 0.53125 / VALID 0.550000011920929\n",
      "10/18/2024 09:14:55 AM Epoch: 90 // Batch 1/2 // loss = 0.67543\n",
      "10/18/2024 09:14:57 AM Epoch: 90 // Batch 2/2 // loss = 0.69145\n",
      "10/18/2024 09:15:10 AM Epoch: 90\n",
      "10/18/2024 09:15:10 AM  [LOSS] TRAIN 0.6931019366989281 / VALID 0.765017196078953\n",
      "10/18/2024 09:15:10 AM  [ACC] TRAIN 0.50625 / VALID 0.3499999940395355\n",
      "10/18/2024 09:15:20 AM Epoch: 91 // Batch 1/2 // loss = 0.68340\n",
      "10/18/2024 09:15:23 AM Epoch: 91 // Batch 2/2 // loss = 0.66194\n",
      "10/18/2024 09:15:36 AM Epoch: 91\n",
      "10/18/2024 09:15:36 AM  [LOSS] TRAIN 0.7105238547817908 / VALID 0.676592651878855\n",
      "10/18/2024 09:15:36 AM  [ACC] TRAIN 0.5625 / VALID 0.6499999761581421\n",
      "10/18/2024 09:15:46 AM Epoch: 92 // Batch 1/2 // loss = 0.69083\n",
      "10/18/2024 09:15:49 AM Epoch: 92 // Batch 2/2 // loss = 0.63233\n",
      "10/18/2024 09:16:02 AM Epoch: 92\n",
      "10/18/2024 09:16:02 AM  [LOSS] TRAIN 0.6948896305346353 / VALID 0.6432785873462341\n",
      "10/18/2024 09:16:02 AM  [ACC] TRAIN 0.4875 / VALID 0.6000000238418579\n",
      "10/18/2024 09:16:12 AM Epoch: 93 // Batch 1/2 // loss = 0.69989\n",
      "10/18/2024 09:16:15 AM Epoch: 93 // Batch 2/2 // loss = 0.67317\n",
      "10/18/2024 09:16:27 AM Epoch: 93\n",
      "10/18/2024 09:16:27 AM  [LOSS] TRAIN 0.6746013089335697 / VALID 0.681948568469759\n",
      "10/18/2024 09:16:27 AM  [ACC] TRAIN 0.5625 / VALID 0.6499999761581421\n",
      "10/18/2024 09:16:38 AM Epoch: 94 // Batch 1/2 // loss = 0.70464\n",
      "10/18/2024 09:16:40 AM Epoch: 94 // Batch 2/2 // loss = 0.68786\n",
      "10/18/2024 09:16:53 AM Epoch: 94\n",
      "10/18/2024 09:16:53 AM  [LOSS] TRAIN 0.6830135874484872 / VALID 0.7120262860989292\n",
      "10/18/2024 09:16:53 AM  [ACC] TRAIN 0.54375 / VALID 0.5\n"
     ]
    }
   ],
   "source": [
    "from meegnet.network import Model\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "save_path = data_path\n",
    "net_option = \"eegnet\"\n",
    "input_size = dataset.data[0].shape\n",
    "n_outputs = 2 # Here we have 100 possible outputs as we have 1 label per subject and 100 subjects\n",
    "name = \"smt_meegnet\"\n",
    "\n",
    "net_params = {\"linear\": 100, \"hlayers\": 3, \"dropout\": .5}\n",
    "my_model = Model(name, net_option, input_size, n_outputs, save_path, net_params=net_params)\n",
    "\n",
    "print(my_model.net)\n",
    "\n",
    "my_model.train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5d515-e730-4435-af07-804dd8dda68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11f1c48-6031-42ed-a13c-1490e698ef1c",
   "metadata": {},
   "source": [
    "It is always possible to access the network inside the Model object if we want to perform single trial predictions for a figure for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0715956d-4c41-455a-ac41-65ded8fdafc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.DoubleTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m random_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22\u001b[39m\n\u001b[1;32m      5\u001b[0m data_example \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata[random_sample][np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;66;03m# need to add a new axis to respect expected shapes, not needed if using multiple examples.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_example\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, original label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlabels[random_sample]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/meegnet/network.py:93\u001b[0m, in \u001b[0;36mcustomNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 93\u001b[0m     feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     94\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassif(feats)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyvenvs/camcan/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.DoubleTensor) should be the same"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random_sample = 22\n",
    "data_example = dataset.data[random_sample][np.newaxis] # need to add a new axis to respect expected shapes, not needed if using multiple examples.\n",
    "\n",
    "pred = my_model.net.forward(torch.Tensor(data_example).cuda())\n",
    "\n",
    "print(f\"predicted label: {np.argmax(pred.detach().cpu().numpy())}, original label: {dataset.labels[random_sample]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e4c46-2da9-4d39-8840-e54932e4db12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
